RANDOM_STATE = 1


import pandas as pd
import time
import numpy as np
import pickle
from sklearn.metrics import confusion_matrix
import warnings
warnings.filterwarnings("ignore")
pd.set_option('display.max_colwidth',300)
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import StackingClassifier
from sklearn.neural_network import MLPClassifier
from imblearn.under_sampling import RandomUnderSampler
from sklearn.utils import shuffle


from nltk.corpus import stopwords
import re
import nltk
from nltk import tokenize
from nltk.stem import WordNetLemmatizer


import spacy


from google.colab import drive
drive.mount('/content/drive')


import math


data_path = '/content/drive/MyDrive/BT4222/data/mbs_reviews.csv'
df = pd.read_csv(data_path)


def rating_clean(rating1, rating2):
  if not math.isnan(rating1):
    return rating1
  return rating2


df["rating"] = df.apply(lambda row: rating_clean(row['rating1'], row['rating2']), axis = 1)


def valid_rating(rating):
  if math.isnan(rating):
    return False
  return True


df['valid_rating'] = df.apply(lambda row: valid_rating(row['rating']), axis = 1)


def classify_rating(rating):
  if rating>=4:
    return "Positive"
  if rating<=2:
    return "Negative"
  return "Neutral"


df["label"] = df.apply(lambda row: classify_rating(row['rating']), axis = 1)


# preprocess function
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
spacy_lemmatizer = spacy.load('en_core_web_sm', disable=['parser','ner'])

def preprocess_text(title, review):


    text = str(title) + " " + str(review)
    # lower text
    text = text.lower()
    # Remove newline characters
    text = text.replace('\\n',' ').replace('\n', ' ').replace('\t', ' ').replace('\r', ' ').replace('\\', ' ')
    # Remove punctuation and numbers
    text = re.sub('[^a-zA-Z]', ' ', text)
    # Remove multiple spaces
    text = re.sub(r'\s+',' ', text)
    # lemmatize
    text = spacy_lemmatizer(text)
    text = [token.lemma_ for token in text]
    # Remove stop words
    text = ' '.join([word for word in text if word not in stop_words])
    # tokenization done below, so no need to do it here.
    return text


df.info()


df.head()


df["cleaned_review"] = df.apply(lambda row: preprocess_text(row['review_title'], row['review_text']), axis = 1)


df.to_csv("/content/drive/MyDrive/BT4222/data/cleaned_mbs_reviews.csv")


valid_df = df[df["valid_rating"]]
valid_df


# Drop neutral
train_df = valid_df[valid_df["label"]!="Neutral"]


train_set, test_set = train_test_split(train_df[['cleaned_review','label']],
                                      test_size=0.2,
                                      shuffle=True,
                                      random_state=RANDOM_STATE)
X_train = train_set.cleaned_review
y_train = train_set.label
X_test = test_set.cleaned_review
y_test = test_set.label


y_train.value_counts()


rus = RandomUnderSampler(random_state=RANDOM_STATE)
X_train, y_train = rus.fit_resample(train_set, train_set['label'])
train_set = shuffle(X_train)
train_set.reset_index(inplace=True, drop=True)


X_train = train_set['cleaned_review']
y_train = train_set['label']


y_train.value_counts()


vectorizer = TfidfVectorizer(use_idf=True,ngram_range=(1,3))
tfidf_features_train = vectorizer.fit_transform(X_train)
tfidf_features_test = vectorizer.transform(X_test)


# save the model to disk
filename = 'tfidf_vectorizer.sav'
pickle.dump(vectorizer, open(filename, 'wb'))

# load the model from disk
#loaded_model = pickle.load(open(filename, 'rb'))


param_grid = {"C":np.logspace(-3,3,7),
              "penalty":["l1","l2"]
              }

lr_model = GridSearchCV(LogisticRegression(),
                        param_grid=param_grid,
                        n_jobs=-1,
                        verbose=5)

#lr_model = LogisticRegression(C=10.0,penalty='l2')
lr_model.fit(tfidf_features_train, y_train)


print('Best Parameters found : {}'.format(lr_model.best_params_))
print('Best Accuracy found : {:.3f}\n'.format(lr_model.best_score_))


predictions = lr_model.predict(tfidf_features_test)
cm = confusion_matrix(y_test, predictions, labels=lr_model.classes_)


disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr_model.classes_)
disp.plot()
plt.show()



t1 = time.time()

predictions = lr_model.predict(tfidf_features_test)
t2 = time.time()
print(f'Time Taken {t2-t1} s, {len(y_test)/(t2-t1)} rows per s')
print(sklearn.metrics.classification_report(y_test, predictions, target_names=['Negative', 'Positive']))
print(sklearn.metrics.confusion_matrix(y_test, predictions, labels=lr_model.classes_))


param_grid =  {'alpha':[0, 0.01, 0.1, 0.5, 1.0, 10.0],
               'fit_prior': [True, False],
               'class_prior': [None, [0.1,]*3]
              }

nb_model = GridSearchCV(MultinomialNB(),
                        param_grid=param_grid,
                        n_jobs=-1,
                        verbose=5)
#nb_model = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)
nb_model.fit(tfidf_features_train, y_train)


print('Best Parameters found : {}'.format(nb_model.best_params_))
print('Best Accuracy found : {:.3f}\n'.format(nb_model.best_score_))


predictions = nb_model.predict(tfidf_features_test)
cm = confusion_matrix(y_test, predictions, labels=nb_model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=nb_model.classes_)
disp.plot()
plt.show()



t1 = time.time()

predictions = nb_model.predict(tfidf_features_test)
t2 = time.time()
print(f'Time Taken {t2-t1} s, {len(y_test)/(t2-t1)} rows per s')
print(sklearn.metrics.classification_report(y_test, predictions, target_names=['Negative', 'Positive']))
print(sklearn.metrics.confusion_matrix(y_test, predictions, labels=nb_model.classes_))


param_grid =  {'C':[0, 0.01, 0.1, 0.5, 1.0, 10.0],
               'dual': [True, False],
               'penalty': ['l1','l2'],
              }

lsvm_model = GridSearchCV(sklearn.svm.LinearSVC(random_state=RANDOM_STATE),
                        param_grid=param_grid,
                        n_jobs=-1,
                        verbose=5)
#lsvm_model = sklearn.svm.LinearSVC(C=1.0,dual=False,penalty='l1')
lsvm_model.fit(tfidf_features_train, y_train)


print('Best Parameters found : {}'.format(lsvm_model.best_params_))
print('Best Accuracy found : {:.3f}\n'.format(lsvm_model.best_score_))


predictions = lsvm_model.predict(tfidf_features_test)
cm = confusion_matrix(y_test, predictions, labels=lsvm_model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lsvm_model.classes_)
disp.plot()
plt.show()


t1 = time.time()

predictions = lsvm_model.predict(tfidf_features_test)
t2 = time.time()
print(f'Time Taken {t2-t1} s, {len(y_test)/(t2-t1)} rows per s')
print(sklearn.metrics.classification_report(y_test, predictions, target_names=['Negative', 'Positive']))
print(sklearn.metrics.confusion_matrix(y_test, predictions, labels=lsvm_model.classes_))


param_grid = {'n_estimators': [100,200],
              'max_features': ['sqrt','log2'],
              'max_depth': [5,10,15],
}

rf_model = GridSearchCV(RandomForestClassifier(),
                        param_grid=param_grid,
                        n_jobs=-1,
                        verbose=5)
#rf_model = RandomForestClassifier(n_estimators=200, max_features='sqrt', max_depth=15)
rf_model.fit(tfidf_features_train, y_train)


print('Best Parameters found : {}'.format(rf_model.best_params_))
print('Best Accuracy found : {:.3f}\n'.format(rf_model.best_score_))


predictions = rf_model.predict(tfidf_features_test)
cm = confusion_matrix(y_test, predictions, labels=rf_model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_model.classes_)
disp.plot()
plt.show()


t1 = time.time()

predictions = rf_model.predict(tfidf_features_test)
t2 = time.time()
print(f'Time Taken {t2-t1} s, {len(y_test)/(t2-t1)} rows per s')
print(sklearn.metrics.classification_report(y_test, predictions, target_names=['Negative', 'Positive']))
print(sklearn.metrics.confusion_matrix(y_test, predictions, labels=rf_model.classes_))



