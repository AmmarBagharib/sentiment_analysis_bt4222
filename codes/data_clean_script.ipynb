{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695284946502,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "XbhdfhA58msr"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7gjrM5d2rFt"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2498,
     "status": "ok",
     "timestamp": 1695284946501,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "jIQzdKEO2hcv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth',300)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "\n",
    "import spacy\n",
    "import os\n",
    "#import pyprojroot.here as here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNwZ7KS62vlr"
   },
   "source": [
    "# Import datasets from drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XViMCq4E3il1"
   },
   "source": [
    "Note - for the purpose of brevity, data has already been preprocessed and cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19315,
     "status": "ok",
     "timestamp": 1695285040903,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "TrJjJAFp2zHG",
    "outputId": "955c85b4-afc0-4111-dead-fa8a972d996e"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FOLDER = \"data\\\\raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = os.listdir(r\"C:\\Nga\\BT4222\\sentiment_analysis_bt4222\\data\\raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crowne-plaza.csv',\n",
       " 'fullerton.csv',\n",
       " 'grand-mercure-sg-roxy.csv',\n",
       " 'holiday-inn-express-clarke-quay.csv',\n",
       " 'hotel-boss.csv',\n",
       " 'hotel-G.csv',\n",
       " 'ibis-sg-bencoolen.csv',\n",
       " 'mbs_total.csv',\n",
       " 'pan-pacific.csv',\n",
       " 'paradox-sg-merchant-court.csv',\n",
       " 'park-regis.csv',\n",
       " 'parkroyal-collection-marina-bay.csv',\n",
       " 'swissotel-the-stamford.csv',\n",
       " 'village-hotel-albert-court-by-far-east-hospitality.csv',\n",
       " 'village-hotel-changi-by-far-east-hospitality.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1695285047288,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "eWYRx4-e2zex"
   },
   "outputs": [],
   "source": [
    "#data_path = '/content/drive/MyDrive/BT4222/data/raw/mbs_total.csv'\n",
    "#df = pd.read_csv(data_path)\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Ratings column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_clean(rating1, rating2):\n",
    "    try:\n",
    "        if not math.isnan(rating1):\n",
    "            return rating1\n",
    "    except:\n",
    "        try:\n",
    "            if not math.isnan(rating2):\n",
    "                return rating2\n",
    "        except:\n",
    "            return None\n",
    "    return rating2\n",
    "\n",
    "def valid_rating(rating):\n",
    "    try:\n",
    "        if math.isnan(rating):\n",
    "            return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def classify_rating(rating):\n",
    "    if rating>=4:\n",
    "        return \"Positive\"\n",
    "    if rating<=2:\n",
    "        return \"Negative\"\n",
    "    if rating == 3:\n",
    "        return \"Neutral\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1695286186465,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "fsTYQ3qS2QTW",
    "outputId": "7ac791ca-9373-451f-8769-bdf0fc6a1d28"
   },
   "outputs": [],
   "source": [
    "#df[\"rating\"] = df.apply(lambda row: rating_clean(row['rating1'], row['rating2']), axis = 1)\n",
    "#df['valid_rating'] = df.apply(lambda row: valid_rating(row['rating']), axis = 1)\n",
    "#df[\"label\"] = df.apply(lambda row: classify_rating(row['rating']), axis = 1)\n",
    "#df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ngalh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# preprocess function\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "spacy_lemmatizer = spacy.load('en_core_web_sm', disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(title, review):\n",
    "    text = str(title) + \" \" + str(review)\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\\\n',' ').replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('\\\\', ' ')\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    # lemmatize\n",
    "    text = spacy_lemmatizer(text)\n",
    "    text = [token.lemma_ for token in text]\n",
    "    # Remove stop words\n",
    "    text = ' '.join([word for word in text if word not in stop_words])\n",
    "    # tokenization done below, so no need to do it here.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"cleaned_review\"] = df.apply(lambda row: preprocess_text(row['review_title'], row['review_text']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Raw title and review, and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine raw title and review\n",
    "def combine(r):\n",
    "  return str(r['review_title']) + \" \" + str(r['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"combined_review\"] = df.apply(lambda row: combine(row), axis = 1)\n",
    "#df['date'] = df['date_of_stay'].str.split(':').str[1]\n",
    "#df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_start = datetime(2020, 1, 29, 0, 0)\n",
    "covid_end = datetime(2022, 4, 1, 0, 0, 0)\n",
    "def get_period(t):\n",
    "    if pd.isnull(t):\n",
    "        return None\n",
    "    if t - covid_start < timedelta(0):\n",
    "        return \"PreCovid\"\n",
    "    elif t-covid_end >= timedelta(0):\n",
    "        return \"PostCovid\"\n",
    "    return \"Covid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"covid\"] = df.apply(lambda row: get_period(row[\"date\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FOLDER = 'data\\\\cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = r'C:\\Nga\\BT4222\\sentiment_analysis_bt4222'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crowne-plaza.csv',\n",
       " 'fullerton.csv',\n",
       " 'grand-mercure-sg-roxy.csv',\n",
       " 'holiday-inn-express-clarke-quay.csv',\n",
       " 'hotel-boss.csv',\n",
       " 'hotel-G.csv',\n",
       " 'ibis-sg-bencoolen.csv',\n",
       " 'mbs_total.csv',\n",
       " 'pan-pacific.csv',\n",
       " 'paradox-sg-merchant-court.csv',\n",
       " 'park-regis.csv',\n",
       " 'parkroyal-collection-marina-bay.csv',\n",
       " 'swissotel-the-stamford.csv',\n",
       " 'village-hotel-albert-court-by-far-east-hospitality.csv',\n",
       " 'village-hotel-changi-by-far-east-hospitality.csv']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(csv):\n",
    "    print(csv)\n",
    "    data_path = ROOT + \"\\\\\"+RAW_FOLDER + \"\\\\\" + csv\n",
    "    df = pd.read_csv(data_path)\n",
    "    df[\"rating\"] = df.apply(lambda row: rating_clean(row['rating1'], row['rating2']), axis = 1)\n",
    "    df['valid_rating'] = df.apply(lambda row: valid_rating(row['rating']), axis = 1)\n",
    "    df[\"label\"] = df.apply(lambda row: classify_rating(row['rating']), axis = 1)\n",
    "    df[\"cleaned_review\"] = df.apply(lambda row: preprocess_text(row['review_title'], row['review_text']), axis = 1)\n",
    "    df[\"combined_review\"] = df.apply(lambda row: combine(row), axis = 1)\n",
    "    df['date'] = df['date_of_stay'].str.split(':').str[1]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"covid\"] = df.apply(lambda row: get_period(row[\"date\"]), axis = 1)\n",
    "    df.to_csv(f\"{ROOT}\\{SAVE_FOLDER}\\cleaned_{csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "village-hotel-changi-by-far-east-hospitality.csv\n"
     ]
    }
   ],
   "source": [
    "for csv in ['village-hotel-changi-by-far-east-hospitality.csv']:\n",
    "    clean_data(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"/content/drive/MyDrive/BT4222/data/cleaned/cleaned_mbs_reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
