{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695284946502,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "XbhdfhA58msr"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7gjrM5d2rFt"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2498,
     "status": "ok",
     "timestamp": 1695284946501,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "jIQzdKEO2hcv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth',300)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyprojroot.here as here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNwZ7KS62vlr"
   },
   "source": [
    "# Import datasets from drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XViMCq4E3il1"
   },
   "source": [
    "Note - for the purpose of brevity, data has already been preprocessed and cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19315,
     "status": "ok",
     "timestamp": 1695285040903,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "TrJjJAFp2zHG",
    "outputId": "955c85b4-afc0-4111-dead-fa8a972d996e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1695285047288,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "eWYRx4-e2zex"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/MyDrive/BT4222/data/raw/crowne-plaza.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/content/drive/MyDrive/BT4222/data/raw/mbs_total.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Ratings column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1695286186465,
     "user": {
      "displayName": "Hien Nga Luong",
      "userId": "10313683531485500593"
     },
     "user_tz": -480
    },
    "id": "fsTYQ3qS2QTW",
    "outputId": "7ac791ca-9373-451f-8769-bdf0fc6a1d28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    5099\n",
       "Neutral      383\n",
       "Negative     261\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rating_clean(rating1, rating2):\n",
    "    if not math.isnan(rating1):\n",
    "        return rating1\n",
    "    return rating2\n",
    "\n",
    "df[\"rating\"] = df.apply(lambda row: rating_clean(row['rating1'], row['rating2']), axis = 1)\n",
    "\n",
    "def valid_rating(rating):\n",
    "    if math.isnan(rating):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df['valid_rating'] = df.apply(lambda row: valid_rating(row['rating']), axis = 1)\n",
    "\n",
    "def classify_rating(rating):\n",
    "    if rating>=4:\n",
    "        return \"Positive\"\n",
    "    if rating<=2:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "df[\"label\"] = df.apply(lambda row: classify_rating(row['rating']), axis = 1)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "spacy_lemmatizer = spacy.load('en_core_web_sm', disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(title, review):\n",
    "\n",
    "\n",
    "    text = str(title) + \" \" + str(review)\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\\\n',' ').replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('\\\\', ' ')\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    # lemmatize\n",
    "    text = spacy_lemmatizer(text)\n",
    "    text = [token.lemma_ for token in text]\n",
    "    # Remove stop words\n",
    "    text = ' '.join([word for word in text if word not in stop_words])\n",
    "    # tokenization done below, so no need to do it here.\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_review\"] = df.apply(lambda row: preprocess_text(row['review_title'], row['review_text']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Raw title and review, and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine raw title and review\n",
    "def combine(r):\n",
    "  return str(r['review_title']) + \" \" + str(r['review_text'])\n",
    "\n",
    "df[\"combined_review\"] = df.apply(lambda row: combine(row), axis = 1)\n",
    "\n",
    "df['date'] = df['date_of_stay'].str.split(':').str[1]\n",
    "df[\"date\"] = pd.to_datetime(data[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_start = datetime(2020, 1, 29, 0, 0)\n",
    "covid_end = datetime(2022, 4, 1, 0, 0, 0)\n",
    "def get_period(t):\n",
    "    if pd.isnull(t):\n",
    "        return None\n",
    "    if t - covid_start < timedelta(0):\n",
    "        return \"PreCovid\"\n",
    "    elif t-covid_end >= timedelta(0):\n",
    "        return \"PostCovid\"\n",
    "    return \"Covid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"covid\"] = data.apply(lambda row: get_period(row[\"date\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/content/drive/MyDrive/BT4222/data/cleaned/cleaned_mbs_reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:bt4222_hotels]",
   "language": "python",
   "name": "conda-env-bt4222_hotels-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
