{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e298f2-0e17-49fe-8534-1c24e3dad6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388f6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f947734a-9c93-4c88-b5e8-0a2c92a5c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "##LDA stuff\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "##cleaning stuff\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "##plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8724485f-111f-4d2b-822c-060a718a6e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 68292 entries, 0 to 98107\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   travel_type      31354 non-null  object \n",
      " 1   rating           54837 non-null  float64\n",
      " 2   label            54837 non-null  object \n",
      " 3   combined_review  68292 non-null  object \n",
      " 4   date             68292 non-null  object \n",
      " 5   covid            68292 non-null  object \n",
      " 6   is_local         68292 non-null  int64  \n",
      " 7   stem_review      68292 non-null  object \n",
      " 8   lem_review       68292 non-null  object \n",
      " 9   cleaned_review   68292 non-null  object \n",
      " 10  star             68292 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 6.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>combined_review</th>\n",
       "      <th>date</th>\n",
       "      <th>covid</th>\n",
       "      <th>is_local</th>\n",
       "      <th>stem_review</th>\n",
       "      <th>lem_review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>couple</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>clean comfortable hotel expensive find decent ...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>clean comfort hotel expens find decent hotel e...</td>\n",
       "      <td>clean comfortable hotel expensive find decent ...</td>\n",
       "      <td>clean comfortable hotel expensive find decent ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>good hotel great locat great place locat great...</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friends</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>great locat great staff ibi neat tidi hotel li...</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good budget stay stayed days nice location sev...</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>good budget stay stay day nice locat seven ele...</td>\n",
       "      <td>good budget stay stay day nice location seven ...</td>\n",
       "      <td>good budget stay stayed days nice location sev...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  travel_type  rating     label  \\\n",
       "0      couple     4.0  Positive   \n",
       "1      family     5.0  Positive   \n",
       "2     friends     5.0  Positive   \n",
       "3        solo     5.0  Positive   \n",
       "4    business     4.0  Positive   \n",
       "\n",
       "                                     combined_review        date      covid  \\\n",
       "0  clean comfortable hotel expensive find decent ...  2023-08-01  PostCovid   \n",
       "1  good hotel great location great place location...  2023-08-01  PostCovid   \n",
       "2  good place decent price good place good price ...  2022-10-01  PostCovid   \n",
       "3  great location great staff ibis neat tidy hote...  2023-08-01  PostCovid   \n",
       "4  good budget stay stayed days nice location sev...  2022-08-01  PostCovid   \n",
       "\n",
       "   is_local                                        stem_review  \\\n",
       "0         0  clean comfort hotel expens find decent hotel e...   \n",
       "1         0  good hotel great locat great place locat great...   \n",
       "2         0  good place decent price good place good price ...   \n",
       "3         0  great locat great staff ibi neat tidi hotel li...   \n",
       "4         0  good budget stay stay day nice locat seven ele...   \n",
       "\n",
       "                                          lem_review  \\\n",
       "0  clean comfortable hotel expensive find decent ...   \n",
       "1  good hotel great location great place location...   \n",
       "2  good place decent price good place good price ...   \n",
       "3  great location great staff ibis neat tidy hote...   \n",
       "4  good budget stay stay day nice location seven ...   \n",
       "\n",
       "                                      cleaned_review  star  \n",
       "0  clean comfortable hotel expensive find decent ...     3  \n",
       "1  good hotel great location great place location...     3  \n",
       "2  good place decent price good place good price ...     3  \n",
       "3  great location great staff ibis neat tidy hote...     3  \n",
       "4  good budget stay stayed days nice location sev...     3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: modify these list if needed (eg. if you want to load only 1 csv from star3, delete other csvs in star3 list)\n",
    "star3 = ['cleaned_ibis-sg-bencoolen.csv','cleaned_hotel-boss.csv','cleaned_hotel-G.csv',\n",
    "           'cleaned_village-hotel-albert-court-by-far-east-hospitality.csv',\n",
    "           'cleaned_holiday-inn-express-clarke-quay.csv']\n",
    "star4 = ['cleaned_village-hotel-changi-by-far-east-hospitality.csv',\n",
    "         'cleaned_park-regis.csv', 'cleaned_grand-mercure-sg-roxy.csv',\n",
    "         'cleaned_paradox-sg-merchant-court.csv','cleaned_crowne-plaza.csv']\n",
    "star5 = ['cleaned_fullerton.csv', 'cleaned_parkroyal-collection-marina-bay.csv', 'cleaned_pan-pacific.csv',\n",
    "          'cleaned_mbs_total.csv', 'cleaned_swissotel-the-stamford.csv']\n",
    "\n",
    "RAW_FOLDER = \"../../data/processed/\"\n",
    "\n",
    "def combine_csv_to_dataframe(file_names, all_star = False, filterDate = True):\n",
    "    \"\"\"\n",
    "    Combine multiple CSV files into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_names (list): List of CSV file names. \n",
    "    all_star (bool): whether or not to load all the hotels (False if only want to load 1 type of hotel star). \n",
    "    filterData (bool): whether or not to remove all data dated before 2015\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_interim_path = RAW_FOLDER + file_name\n",
    "        file_path = file_interim_path\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            if all_star:\n",
    "                if file_name in star3:\n",
    "                    df[\"star\"] = 3\n",
    "                elif file_name in star4:\n",
    "                    df[\"star\"] = 4\n",
    "                else:\n",
    "                    df[\"star\"] = 5\n",
    "            #print(f\"Length of {file_name} is {len(df)}\")\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            #print(len(combined_df))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Empty or invalid CSV file: {file_name}\")\n",
    "            \n",
    "    combined_df = combined_df[combined_df['date'] >= '2015-01-01']\n",
    "                                \n",
    "    return combined_df\n",
    "data = combine_csv_to_dataframe(star3+star4+star5, all_star = True, filterDate = True)\n",
    "#data[['traveller_username','date','travel_type','traveller_total_contributions','traveller_total_helpful_contributions','review_title','review_text','rating']].head(5)\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61de02b3-e7e4-4a93-86bb-782c3476600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = data.query('star==3')\n",
    "df4 = data.query('star==4')\n",
    "df5 = data.query('star==5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b733c49-033f-4a40-96fd-487695f9d0cf",
   "metadata": {},
   "source": [
    "# Assign LDA topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161fd01a-cb19-4e31-908a-26f8eb27f249",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda3 = [(0,\n",
    "  [('room', 0.028019654),\n",
    "   ('shower', 0.02429848),\n",
    "   ('water', 0.02003805),\n",
    "   ('good', 0.016749734),\n",
    "   ('bathroom', 0.016249016),\n",
    "   ('small', 0.015367531),\n",
    "   ('pool', 0.014033569),\n",
    "   ('area', 0.01364396),\n",
    "   ('well', 0.0131019065),\n",
    "   ('bed', 0.012332016),\n",
    "   ('hot', 0.012192612),\n",
    "   ('floor', 0.011816955),\n",
    "   ('also', 0.01121319),\n",
    "   ('space', 0.010460705),\n",
    "   ('free', 0.010154055),\n",
    "   ('breakfast', 0.00998285),\n",
    "   ('use', 0.009889977),\n",
    "   ('one', 0.009070871),\n",
    "   ('avail', 0.008202699),\n",
    "   ('high', 0.008031354)]),\n",
    " (1,\n",
    "  [('room', 0.048877396),\n",
    "   ('hotel', 0.035052437),\n",
    "   ('small', 0.017294107),\n",
    "   ('one', 0.015194208),\n",
    "   ('stay', 0.01469374),\n",
    "   ('night', 0.014450712),\n",
    "   ('get', 0.011605806),\n",
    "   ('us', 0.011314762),\n",
    "   ('breakfast', 0.010594836),\n",
    "   ('even', 0.009225123),\n",
    "   ('book', 0.009213377),\n",
    "   ('bed', 0.008568587),\n",
    "   ('could', 0.008473515),\n",
    "   ('time', 0.0076296735),\n",
    "   ('day', 0.0072289393),\n",
    "   ('bad', 0.0071428926),\n",
    "   ('size', 0.007104914),\n",
    "   ('like', 0.006724387),\n",
    "   ('good', 0.0066856826),\n",
    "   ('would', 0.0066501293)]),\n",
    " (2,\n",
    "  [('hotel', 0.06546004),\n",
    "   ('good', 0.043226086),\n",
    "   ('great', 0.033812556),\n",
    "   ('breakfast', 0.030543184),\n",
    "   ('stay', 0.028642496),\n",
    "   ('room', 0.023268161),\n",
    "   ('walk', 0.022442635),\n",
    "   ('nice', 0.020002468),\n",
    "   ('staff', 0.019089388),\n",
    "   ('clean', 0.018949142),\n",
    "   ('small', 0.0176249),\n",
    "   ('pool', 0.01545591),\n",
    "   ('well', 0.01282588),\n",
    "   ('comfort', 0.011138362),\n",
    "   ('food', 0.011052815),\n",
    "   ('night', 0.010776383),\n",
    "   ('area', 0.010553828),\n",
    "   ('excel', 0.010348529),\n",
    "   ('close', 0.010164016),\n",
    "   ('also', 0.009887687)]),\n",
    " (3,\n",
    "  [('hotel', 0.061234057),\n",
    "   ('stay', 0.04743017),\n",
    "   ('staff', 0.04123435),\n",
    "   ('room', 0.031478345),\n",
    "   ('check', 0.030055951),\n",
    "   ('great', 0.02450151),\n",
    "   ('us', 0.02277084),\n",
    "   ('help', 0.021023287),\n",
    "   ('good', 0.02054956),\n",
    "   ('time', 0.015681427),\n",
    "   ('thank', 0.014486463),\n",
    "   ('nice', 0.012198553),\n",
    "   ('clean', 0.011541337),\n",
    "   ('day', 0.010844667),\n",
    "   ('front', 0.010427587),\n",
    "   ('would', 0.010189428),\n",
    "   ('back', 0.0100764185),\n",
    "   ('come', 0.009442571),\n",
    "   ('alway', 0.0092536835),\n",
    "   ('also', 0.00901258)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5f717f-72d5-49fd-bd3d-e80047a559b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda4 = [(0,\n",
    "  [('hotel', 0.06066543),\n",
    "   ('good', 0.05662687),\n",
    "   ('great', 0.051247127),\n",
    "   ('stay', 0.039658293),\n",
    "   ('pool', 0.036424354),\n",
    "   ('room', 0.035750892),\n",
    "   ('nice', 0.03357231),\n",
    "   ('staff', 0.031510737),\n",
    "   ('breakfast', 0.030704545),\n",
    "   ('clean', 0.022773447),\n",
    "   ('comfort', 0.020109307),\n",
    "   ('excel', 0.019477336),\n",
    "   ('well', 0.018372677),\n",
    "   ('help', 0.013885156),\n",
    "   ('would', 0.013775486),\n",
    "   ('food', 0.01340219),\n",
    "   ('buffet', 0.012523241),\n",
    "   ('love', 0.010999166),\n",
    "   ('area', 0.010570749),\n",
    "   ('night', 0.010390278)]),\n",
    " (1,\n",
    "  [('room', 0.06312547),\n",
    "   ('check', 0.017642308),\n",
    "   ('hotel', 0.01647614),\n",
    "   ('bed', 0.011348137),\n",
    "   ('bathroom', 0.010589932),\n",
    "   ('one', 0.010202156),\n",
    "   ('book', 0.010044039),\n",
    "   ('shower', 0.009454524),\n",
    "   ('time', 0.009368337),\n",
    "   ('good', 0.00930641),\n",
    "   ('get', 0.00887617),\n",
    "   ('floor', 0.008515672),\n",
    "   ('like', 0.00827102),\n",
    "   ('even', 0.0077712038),\n",
    "   ('could', 0.0072875964),\n",
    "   ('night', 0.0071407855),\n",
    "   ('would', 0.007056457),\n",
    "   ('us', 0.006762563),\n",
    "   ('stay', 0.006739076),\n",
    "   ('work', 0.006467629)]),\n",
    " (2,\n",
    "  [('stay', 0.04730338),\n",
    "   ('hotel', 0.046276893),\n",
    "   ('staff', 0.0447593),\n",
    "   ('us', 0.023029383),\n",
    "   ('great', 0.021268932),\n",
    "   ('help', 0.018108215),\n",
    "   ('time', 0.016622065),\n",
    "   ('thank', 0.01511681),\n",
    "   ('excel', 0.0143885),\n",
    "   ('room', 0.014370245),\n",
    "   ('alway', 0.01285341),\n",
    "   ('back', 0.011351997),\n",
    "   ('day', 0.009717909),\n",
    "   ('wonder', 0.009487917),\n",
    "   ('best', 0.009451669),\n",
    "   ('club', 0.008978278),\n",
    "   ('love', 0.008878429),\n",
    "   ('would', 0.008704857),\n",
    "   ('make', 0.0085479645),\n",
    "   ('made', 0.008402818)]),\n",
    " (3,\n",
    "  [('airport', 0.06567468),\n",
    "   ('hotel', 0.06527326),\n",
    "   ('stay', 0.032393623),\n",
    "   ('termin', 0.0260096),\n",
    "   ('flight', 0.025122376),\n",
    "   ('room', 0.02438863),\n",
    "   ('night', 0.01972968),\n",
    "   ('check', 0.019121783),\n",
    "   ('one', 0.014915458),\n",
    "   ('get', 0.01162541),\n",
    "   ('comfort', 0.011361008),\n",
    "   ('time', 0.010810979),\n",
    "   ('walk', 0.010133061),\n",
    "   ('transit', 0.009941516),\n",
    "   ('long', 0.009932345),\n",
    "   ('next', 0.0096626645),\n",
    "   ('morn', 0.009263578),\n",
    "   ('day', 0.009244583),\n",
    "   ('overnight', 0.009122408),\n",
    "   ('late', 0.008109804)]),\n",
    " (4,\n",
    "  [('hotel', 0.06364555),\n",
    "   ('walk', 0.033848412),\n",
    "   ('good', 0.026078753),\n",
    "   ('shop', 0.023754375),\n",
    "   ('great', 0.022542689),\n",
    "   ('food', 0.022338388),\n",
    "   ('also', 0.017887287),\n",
    "   ('close', 0.015937222),\n",
    "   ('near', 0.01474164),\n",
    "   ('station', 0.014280471),\n",
    "   ('free', 0.013040087),\n",
    "   ('across', 0.013000975),\n",
    "   ('area', 0.01297331),\n",
    "   ('road', 0.012972581),\n",
    "   ('nice', 0.012285239),\n",
    "   ('bu', 0.012045242),\n",
    "   ('town', 0.011958242),\n",
    "   ('pool', 0.0113485195),\n",
    "   ('away', 0.010629319),\n",
    "   ('mall', 0.010490889)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19228e4c-887c-4552-aee3-b72e9eb99966",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda5 = [(0,\n",
    "  [('hotel', 0.061920475),\n",
    "   ('pool', 0.034780033),\n",
    "   ('view', 0.0328016),\n",
    "   ('great', 0.028055392),\n",
    "   ('stay', 0.026859544),\n",
    "   ('room', 0.026566213),\n",
    "   ('bay', 0.021528374),\n",
    "   ('good', 0.01875146),\n",
    "   ('night', 0.014018549),\n",
    "   ('nice', 0.013574248),\n",
    "   ('shop', 0.01347775),\n",
    "   ('floor', 0.013061163),\n",
    "   ('breakfast', 0.011596192),\n",
    "   ('one', 0.009716363),\n",
    "   ('well', 0.0096779065),\n",
    "   ('also', 0.009599337),\n",
    "   ('walk', 0.009585248),\n",
    "   ('mall', 0.008831545),\n",
    "   ('food', 0.008742659),\n",
    "   ('place', 0.008587227)]),\n",
    " (1,\n",
    "  [('food', 0.07006818),\n",
    "   ('good', 0.050391592),\n",
    "   ('tea', 0.038146388),\n",
    "   ('great', 0.037390612),\n",
    "   ('restaur', 0.029425347),\n",
    "   ('afternoon', 0.027223198),\n",
    "   ('dinner', 0.024779718),\n",
    "   ('buffet', 0.024768097),\n",
    "   ('swiss', 0.021368127),\n",
    "   ('nice', 0.019505108),\n",
    "   ('excel', 0.017836131),\n",
    "   ('staff', 0.015534015),\n",
    "   ('attent', 0.011996699),\n",
    "   ('lunch', 0.011778906),\n",
    "   ('select', 0.01161212),\n",
    "   ('love', 0.011317591),\n",
    "   ('dine', 0.0109803695),\n",
    "   ('well', 0.010426343),\n",
    "   ('breakfast', 0.00999563),\n",
    "   ('come', 0.009959913)]),\n",
    " (2,\n",
    "  [('room', 0.04861536),\n",
    "   ('check', 0.026507057),\n",
    "   ('hotel', 0.02609595),\n",
    "   ('time', 0.014249958),\n",
    "   ('stay', 0.01398844),\n",
    "   ('get', 0.0125461705),\n",
    "   ('one', 0.011784243),\n",
    "   ('would', 0.010396946),\n",
    "   ('book', 0.010188739),\n",
    "   ('night', 0.0097509865),\n",
    "   ('even', 0.00857634),\n",
    "   ('pool', 0.008448032),\n",
    "   ('like', 0.0081832325),\n",
    "   ('day', 0.008071083),\n",
    "   ('could', 0.00775153),\n",
    "   ('floor', 0.007650544),\n",
    "   ('go', 0.0075336895),\n",
    "   ('staff', 0.007229006),\n",
    "   ('bed', 0.0070900335),\n",
    "   ('wait', 0.0066880765)]),\n",
    " (3,\n",
    "  [('us', 0.059095435),\n",
    "   ('birthday', 0.02917478),\n",
    "   ('thank', 0.017529981),\n",
    "   ('check', 0.01695204),\n",
    "   ('cake', 0.014356298),\n",
    "   ('wed', 0.013660884),\n",
    "   ('also', 0.012656271),\n",
    "   ('day', 0.012325384),\n",
    "   ('special', 0.012037271),\n",
    "   ('team', 0.01169118),\n",
    "   ('made', 0.011527236),\n",
    "   ('even', 0.0111270845),\n",
    "   ('gave', 0.010920424),\n",
    "   ('park', 0.010272152),\n",
    "   ('make', 0.010252163),\n",
    "   ('n', 0.009127772),\n",
    "   ('wife', 0.008447073),\n",
    "   ('went', 0.008130026),\n",
    "   ('help', 0.007957786),\n",
    "   ('staff', 0.0075411727)]),\n",
    " (4,\n",
    "  [('stay', 0.06459443),\n",
    "   ('hotel', 0.053955726),\n",
    "   ('staff', 0.051875144),\n",
    "   ('great', 0.034243435),\n",
    "   ('club', 0.024310365),\n",
    "   ('room', 0.023868028),\n",
    "   ('help', 0.020169307),\n",
    "   ('excel', 0.019916743),\n",
    "   ('time', 0.016955014),\n",
    "   ('would', 0.014386054),\n",
    "   ('best', 0.01415547),\n",
    "   ('back', 0.012771573),\n",
    "   ('wonder', 0.011836362),\n",
    "   ('alway', 0.010785513),\n",
    "   ('us', 0.010444606),\n",
    "   ('thank', 0.010332707),\n",
    "   ('well', 0.010328791),\n",
    "   ('fantast', 0.009910117),\n",
    "   ('love', 0.009776346),\n",
    "   ('made', 0.009334151)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c744b3-4d68-40c7-9e89-ce45863a2027",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eeb82b6-7198-4664-b67b-dd3c8dd2d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Pass in LDA topics output to remove overlap words by choosing highest prob\n",
    "def restruct_topics(topics): \n",
    "    word_prob_dict = {}\n",
    "    for i in range(len(topics)):\n",
    "        topic_num = topics[i][0]\n",
    "        for word, prob in topics[i][1]:\n",
    "            if word in word_prob_dict:\n",
    "                word_prob_dict[word].append((topic_num, prob))\n",
    "            else:\n",
    "                ls = [(topic_num, prob)]\n",
    "                word_prob_dict[word] = ls\n",
    "    new_dict = {}\n",
    "    for word in word_prob_dict:\n",
    "        topic, highest_prob = max(word_prob_dict[word], key = lambda x: x[1])\n",
    "        if topic in new_dict:\n",
    "            new_dict[topic].append(word)\n",
    "        else:\n",
    "            ls = [word]\n",
    "            new_dict[topic] = ls\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4673a96-5778-4999-a892-45ac7995ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8469712e-b2c9-4126-b677-bd674e459ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in the dataframe and appends to each row (aspect, review) pair(s)\n",
    "def dep_parse(data, new_dict):\n",
    "    data['aspect_sentiment'] = np.empty((len(data), 0)).tolist()\n",
    "    for i in range(len(data)):\n",
    "        #print(i)\n",
    "        sentence = data['combined_review'][i]\n",
    "        doc = nlp(sentence)\n",
    "        aspect_sentiment = []\n",
    "        for word in doc:\n",
    "            cond = False\n",
    "            for x in new_dict.values():\n",
    "                if word.text in x:\n",
    "                    cond = True\n",
    "                    break\n",
    "            if not cond:\n",
    "                continue\n",
    "            if word.pos_ == 'NOUN': \n",
    "                for j in word.lefts:\n",
    "                    #print(j, word, j.dep_, j.pos_)\n",
    "                    if j.dep_ == 'amod' and j.pos_ == 'ADJ':\n",
    "                        tup = [word, j, list(new_dict.values()).index(x)]\n",
    "                        #print(tup)\n",
    "                        aspect_sentiment.append(tup)\n",
    "                    for k in j.lefts:\n",
    "                        if k.dep_ == 'advmod':\n",
    "                            #print(word, j ,k)\n",
    "                            tup = [word, k.text + ' ' + j.text, list(new_dict.values()).index(x)]\n",
    "                            aspect_sentiment.append(tup)\n",
    "                            if (word, j) in aspect_sentiment:\n",
    "                                aspect_sentiment.remove([word, j, list(new_dict.values()).index(x)])\n",
    "        data['aspect_sentiment'][i] = aspect_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed3e814-98a9-4db3-974b-b8f4e5d0ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.reset_index(drop=True)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df5 = df5.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5904873-f2ef-4bdc-877f-e0466ad528e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_parse(df3, restruct_topics(lda3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6164a170-0b9f-4837-b2c7-f2d10b5a93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_parse(df4, restruct_topics(lda4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a126fb7b-69de-43f5-8f35-aa8b75d9eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_parse(df5, restruct_topics(lda5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a64ee-12ef-4219-ae2f-80789338c625",
   "metadata": {},
   "source": [
    "# Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9472696-c518-44a6-ad08-25bee7bc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e260f05-988a-4483-a8e2-8576983eaeab",
   "metadata": {},
   "source": [
    "## Mean Textblob Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3349b1c-aa68-40b4-b87c-1ffcfe04b766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate mean TextBlob polarity for each topic\n",
    "def calculate_mean_textblob_polarity(row):\n",
    "    scores = {}\n",
    "    counts = {}\n",
    "    \n",
    "    for aspect_sentiment in row:\n",
    "        aspect = aspect_sentiment[0]\n",
    "        adjective = aspect_sentiment[1]\n",
    "        topic = aspect_sentiment[2]\n",
    "\n",
    "        # Concatenate aspect and adjective\n",
    "        text_to_analyze = f\"{aspect} {adjective}\"\n",
    "\n",
    "        # Calculate TextBlob polarity\n",
    "        polarity = TextBlob(text_to_analyze).sentiment.polarity\n",
    "\n",
    "        # Accumulate polarity values of each aspect within a topic\n",
    "        column_name = f'topic_{topic}'\n",
    "        scores[column_name] = scores.get(column_name, 0) + polarity # add polarity to existing polarity (if have)\n",
    "        # if a topic occurence is more than once, scores[column_name] will be the summed polarity\n",
    "\n",
    "        # Count occurrences of each aspect within a topic\n",
    "        count_column_name = f'count_{column_name}'\n",
    "        counts[count_column_name] = counts.get(count_column_name, 0) + 1\n",
    "    \n",
    "    # Calculate mean polarity for each topic\n",
    "    for count_column_name, topic_count in counts.items():\n",
    "        #print(counts.items())\n",
    "        column_name = count_column_name.replace('count_', '')\n",
    "        mean_polarity = scores[column_name] / counts[count_column_name]\n",
    "        scores[column_name] = mean_polarity # replace summed polarity with mean polarity\n",
    "\n",
    "    return pd.Series({**scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0271b3b6-f84b-401b-a100-64a20022879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"combined_review\", \"date\", \"stem_review\", \"lem_review\", \"star\", \"cleaned_review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eba26c67-45e4-4c12-8318-8941dbc81d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14070, 17)\n",
      "(12331, 17)\n"
     ]
    }
   ],
   "source": [
    "result_df3 = df3['aspect_sentiment'].apply(calculate_mean_textblob_polarity)\n",
    "result_df3[\"overall_textblob_polarity\"] = df3.apply(lambda row: TextBlob(row[\"combined_review\"]).sentiment.polarity, axis = 1)\n",
    "\n",
    "# Concatenate the result DataFrame with df_subset\n",
    "df3_with_scores = pd.concat([df3, result_df3], axis=1)\n",
    "\n",
    "df3_final = df3_with_scores[df3_with_scores['aspect_sentiment'].apply(lambda x: bool(x))] \n",
    "print(df3_with_scores.shape)\n",
    "print(df3_final.shape)\n",
    "df3_final = df3_final.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b85e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>covid</th>\n",
       "      <th>is_local</th>\n",
       "      <th>aspect_sentiment</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>overall_textblob_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>couple</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>[[hotel, clean, 2], [hotel, comfortable, 2], [...</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>[[room, great, 0], [room, small, 0], [hotel, g...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friends</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>[[food, close, 2], [check, easy, 3]]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.396296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>[[staff, great, 3]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.312083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>0</td>\n",
       "      <td>[[room, also night, 0], [time, long, 3]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.372917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  travel_type  rating     label      covid  is_local  \\\n",
       "0      couple     4.0  Positive  PostCovid         0   \n",
       "1      family     5.0  Positive  PostCovid         0   \n",
       "2     friends     5.0  Positive  PostCovid         0   \n",
       "3        solo     5.0  Positive  PostCovid         0   \n",
       "4    business     4.0  Positive  PostCovid         0   \n",
       "\n",
       "                                    aspect_sentiment   topic_2   topic_0  \\\n",
       "0  [[hotel, clean, 2], [hotel, comfortable, 2], [...  0.311111  0.143333   \n",
       "1  [[room, great, 0], [room, small, 0], [hotel, g...  0.700000  0.275000   \n",
       "2               [[food, close, 2], [check, easy, 3]]  0.000000       NaN   \n",
       "3                                [[staff, great, 3]]       NaN       NaN   \n",
       "4           [[room, also night, 0], [time, long, 3]]       NaN  0.000000   \n",
       "\n",
       "    topic_1   topic_3  overall_textblob_polarity  \n",
       "0  0.205556       NaN                   0.149749  \n",
       "1       NaN       NaN                   0.455000  \n",
       "2       NaN  0.433333                   0.396296  \n",
       "3       NaN  0.800000                   0.312083  \n",
       "4       NaN -0.050000                   0.372917  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61418ea1-d527-40e7-9dfa-4cb98578e988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18600, 18)\n",
      "(16349, 18)\n"
     ]
    }
   ],
   "source": [
    "result_df4 = df4['aspect_sentiment'].apply(calculate_mean_textblob_polarity)\n",
    "result_df4[\"overall_textblob_polarity\"] = df4.apply(lambda row: TextBlob(row[\"combined_review\"]).sentiment.polarity, axis = 1)\n",
    "\n",
    "# Concatenate the result DataFrame with df_subset\n",
    "df4_with_scores = pd.concat([df4, result_df4], axis=1)\n",
    "\n",
    "df4_final = df4_with_scores[df4_with_scores['aspect_sentiment'].apply(lambda x: bool(x))]\n",
    "print(df4_with_scores.shape)\n",
    "print(df4_final.shape)\n",
    "df4_final = df4_final.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "011184ff-e84f-4c59-873c-f05b23dff644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35622, 18)\n",
      "(30972, 18)\n"
     ]
    }
   ],
   "source": [
    "result_df5 = df5['aspect_sentiment'].apply(calculate_mean_textblob_polarity)\n",
    "result_df5[\"overall_textblob_polarity\"] = df5.apply(lambda row: TextBlob(row[\"combined_review\"]).sentiment.polarity, axis = 1)\n",
    "\n",
    "# Concatenate the result DataFrame with df_subset\n",
    "df5_with_scores = pd.concat([df5, result_df5], axis=1)\n",
    "\n",
    "df5_final = df5_with_scores[df5_with_scores['aspect_sentiment'].apply(lambda x: bool(x))]\n",
    "print(df5_with_scores.shape)\n",
    "print(df5_final.shape)\n",
    "df5_final = df5_final.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e6dace4-3e9d-4dc9-a2dc-15012990e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name3 = \"../../data/textblob/dp_textblob_3_star.csv\"\n",
    "df3_final.to_csv(csv_name3, index=False)\n",
    "\n",
    "csv_name4 = \"../../data/textblob/dp_textblob_4_star.csv\"\n",
    "df4_final.to_csv(csv_name4, index=False)\n",
    "\n",
    "csv_name5 = \"../../data/textblob/dp_textblob_5_star.csv\"\n",
    "df5_final.to_csv(csv_name5, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
