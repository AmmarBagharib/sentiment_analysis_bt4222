{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e298f2-0e17-49fe-8534-1c24e3dad6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388f6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "##LDA stuff\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "##cleaning stuff\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "##plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pyprojroot.here as here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52879fe2-7fad-44a2-8b67-67d5d4964ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify these list if needed (eg. if you want to load only 1 csv from star3, delete other csvs in star3 list)\n",
    "star3 = ['cleaned_ibis-sg-bencoolen.csv','cleaned_hotel-boss.csv','cleaned_hotel-G.csv',\n",
    "           'cleaned_village-hotel-albert-court-by-far-east-hospitality.csv',\n",
    "           'cleaned_holiday-inn-express-clarke-quay.csv']\n",
    "star4 = ['cleaned_village-hotel-changi-by-far-east-hospitality.csv',\n",
    "         'cleaned_park-regis.csv', 'cleaned_grand-mercure-sg-roxy.csv',\n",
    "         'cleaned_paradox-sg-merchant-court.csv','cleaned_crowne-plaza.csv']\n",
    "star5 = ['cleaned_fullerton.csv', 'cleaned_parkroyal-collection-marina-bay.csv', 'cleaned_pan-pacific.csv',\n",
    "          'cleaned_mbs_total.csv', 'cleaned_swissotel-the-stamford.csv']\n",
    "\n",
    "RAW_FOLDER = \"data/processed/\"\n",
    "\n",
    "def combine_csv_to_dataframe(file_names, all_star = False, filterDate = True):\n",
    "    \"\"\"\n",
    "    Combine multiple CSV files into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_names (list): List of CSV file names. \n",
    "    all_star (bool): whether or not to load all the hotels (False if only want to load 1 type of hotel star). \n",
    "    filterData (bool): whether or not to remove all data dated before 2015\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_interim_path = RAW_FOLDER + file_name\n",
    "        file_path = here(file_interim_path)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            if all_star:\n",
    "                if file_name in star3:\n",
    "                    df[\"star\"] = 3\n",
    "                elif file_name in star4:\n",
    "                    df[\"star\"] = 4\n",
    "                else:\n",
    "                    df[\"star\"] = 5\n",
    "            #print(f\"Length of {file_name} is {len(df)}\")\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            #print(len(combined_df))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Empty or invalid CSV file: {file_name}\")\n",
    "            \n",
    "    combined_df = combined_df[combined_df.year > 2000]\n",
    "                    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbffda95-0542-480a-80a0-9d63275fcf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68292 entries, 0 to 68291\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Unnamed: 0                             68292 non-null  int64  \n",
      " 1   traveller_username                     68292 non-null  object \n",
      " 2   review_title                           68253 non-null  object \n",
      " 3   review_text                            68292 non-null  object \n",
      " 4   travel_type                            31354 non-null  object \n",
      " 5   traveller_country_origin               51724 non-null  object \n",
      " 6   traveller_total_contributions          68103 non-null  object \n",
      " 7   traveller_total_helpful_contributions  54090 non-null  float64\n",
      " 8   rating                                 54837 non-null  float64\n",
      " 9   valid_rating                           68292 non-null  bool   \n",
      " 10  label                                  54837 non-null  object \n",
      " 11  cleaned_review                         68292 non-null  object \n",
      " 12  combined_review                        68292 non-null  object \n",
      " 13  date                                   68292 non-null  object \n",
      " 14  covid                                  68292 non-null  object \n",
      " 15  year                                   68292 non-null  int64  \n",
      " 16  stem_review                            68292 non-null  object \n",
      " 17  lem_review                             68292 non-null  object \n",
      " 18  star                                   68292 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(3), object(13)\n",
      "memory usage: 9.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>traveller_username</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>travel_type</th>\n",
       "      <th>traveller_country_origin</th>\n",
       "      <th>traveller_total_contributions</th>\n",
       "      <th>traveller_total_helpful_contributions</th>\n",
       "      <th>rating</th>\n",
       "      <th>valid_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>combined_review</th>\n",
       "      <th>date</th>\n",
       "      <th>covid</th>\n",
       "      <th>year</th>\n",
       "      <th>stem_review</th>\n",
       "      <th>lem_review</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Love_Life_Sydney</td>\n",
       "      <td>Clean and comfortable</td>\n",
       "      <td>Hotel rooms in Singapore are so expensive so t...</td>\n",
       "      <td>Trip type: Travelled as a couple</td>\n",
       "      <td>Sydney, Australia</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>clean comfortable hotel rooms singapore expens...</td>\n",
       "      <td>Clean and comfortable Hotel rooms in Singapore...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2023</td>\n",
       "      <td>clean comfort hotel room singapor expens find ...</td>\n",
       "      <td>clean comfortable hotel room singapore expensi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bilal S</td>\n",
       "      <td>Good hotel, great location</td>\n",
       "      <td>This is a great place! Location is great but t...</td>\n",
       "      <td>Trip type: Travelled with family</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>Good hotel, great location  This is a great pl...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2023</td>\n",
       "      <td>good hotel great locat great place locat great...</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anthony Fernando</td>\n",
       "      <td>Good place for a decent price.</td>\n",
       "      <td>Good place good price  Easy access to the city...</td>\n",
       "      <td>Trip type: Travelled with friends</td>\n",
       "      <td>Dubai, United Arab Emirates</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>Good place for a decent price. Good place good...</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2022</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mjkc204</td>\n",
       "      <td>Great Location and great staff.</td>\n",
       "      <td>The IBIS was a neat and tidy hotel in line wit...</td>\n",
       "      <td>Trip type: Travelled solo</td>\n",
       "      <td>Ellenbrook, Australia</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>Great Location and great staff. The IBIS was a...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2023</td>\n",
       "      <td>great locat great staff ibi neat tidi hotel li...</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aung Nanda</td>\n",
       "      <td>Good for budget stay.</td>\n",
       "      <td>I stayed there for 7 days. It was a nice locat...</td>\n",
       "      <td>Trip type: Travelled on business</td>\n",
       "      <td>Dubai, United Arab Emirates</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good budget stay stayed days nice location sev...</td>\n",
       "      <td>Good for budget stay. I stayed there for 7 day...</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2022</td>\n",
       "      <td>good budget stay stay day nice locat seven ele...</td>\n",
       "      <td>good budget stay stay day nice location seven ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 traveller_username                     review_title  \\\n",
       "0           0   Love_Life_Sydney            Clean and comfortable   \n",
       "1           1            Bilal S      Good hotel, great location    \n",
       "2           2   Anthony Fernando   Good place for a decent price.   \n",
       "3           3            Mjkc204  Great Location and great staff.   \n",
       "4           4         Aung Nanda            Good for budget stay.   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  Hotel rooms in Singapore are so expensive so t...   \n",
       "1  This is a great place! Location is great but t...   \n",
       "2  Good place good price  Easy access to the city...   \n",
       "3  The IBIS was a neat and tidy hotel in line wit...   \n",
       "4  I stayed there for 7 days. It was a nice locat...   \n",
       "\n",
       "                         travel_type     traveller_country_origin  \\\n",
       "0   Trip type: Travelled as a couple            Sydney, Australia   \n",
       "1   Trip type: Travelled with family               Houston, Texas   \n",
       "2  Trip type: Travelled with friends  Dubai, United Arab Emirates   \n",
       "3          Trip type: Travelled solo        Ellenbrook, Australia   \n",
       "4   Trip type: Travelled on business  Dubai, United Arab Emirates   \n",
       "\n",
       "  traveller_total_contributions  traveller_total_helpful_contributions  \\\n",
       "0                        2302.0                                  871.0   \n",
       "1                           4.0                                    NaN   \n",
       "2                          39.0                                   38.0   \n",
       "3                          37.0                                   19.0   \n",
       "4                           3.0                                    4.0   \n",
       "\n",
       "   rating  valid_rating     label  \\\n",
       "0     4.0          True  Positive   \n",
       "1     5.0          True  Positive   \n",
       "2     5.0          True  Positive   \n",
       "3     5.0          True  Positive   \n",
       "4     4.0          True  Positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  clean comfortable hotel rooms singapore expens...   \n",
       "1  good hotel great location great place location...   \n",
       "2  good place decent price good place good price ...   \n",
       "3  great location great staff ibis neat tidy hote...   \n",
       "4  good budget stay stayed days nice location sev...   \n",
       "\n",
       "                                     combined_review        date      covid  \\\n",
       "0  Clean and comfortable Hotel rooms in Singapore...  2023-08-01  PostCovid   \n",
       "1  Good hotel, great location  This is a great pl...  2023-08-01  PostCovid   \n",
       "2  Good place for a decent price. Good place good...  2022-10-01  PostCovid   \n",
       "3  Great Location and great staff. The IBIS was a...  2023-08-01  PostCovid   \n",
       "4  Good for budget stay. I stayed there for 7 day...  2022-08-01  PostCovid   \n",
       "\n",
       "   year                                        stem_review  \\\n",
       "0  2023  clean comfort hotel room singapor expens find ...   \n",
       "1  2023  good hotel great locat great place locat great...   \n",
       "2  2022  good place decent price good place good price ...   \n",
       "3  2023  great locat great staff ibi neat tidi hotel li...   \n",
       "4  2022  good budget stay stay day nice locat seven ele...   \n",
       "\n",
       "                                          lem_review  star  \n",
       "0  clean comfortable hotel room singapore expensi...     3  \n",
       "1  good hotel great location great place location...     3  \n",
       "2  good place decent price good place good price ...     3  \n",
       "3  great location great staff ibis neat tidy hote...     3  \n",
       "4  good budget stay stay day nice location seven ...     3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combine_csv_to_dataframe(star3+star4+star5, all_star = True, filterDate = True)\n",
    "#data[['traveller_username','date','travel_type','traveller_total_contributions','traveller_total_helpful_contributions','review_title','review_text','rating']].head(5)\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d567b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97f5374-d523-4d29-8922-3ba3e1699c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def remove_non_english_words(text, valid_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    ans = [w for w in tokens if w.lower() in valid_words]\n",
    "    return ' '.join(ans)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    ans = [w for w in tokens if w.lower() not in stop_words]\n",
    "    return ' '.join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a21302-21a6-43bf-b38f-fe98d31a5018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35622, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filter for 5 star hotels and year >= 2015\n",
    "df_filtered = data.query('star==5 & year>= 2015')\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c68695-2823-458d-8b8a-8cbdb2b7a880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ammarbagharib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/ammarbagharib/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##preprocess text\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "# Get the list of valid English words\n",
    "english_words = set(words.words())\n",
    "# set stopwords\n",
    "sw = stopwords.words('english')\n",
    "sw.append('fullerton')\n",
    "sw.append('parkroyal')\n",
    "sw.append('marina_bay')\n",
    "sw.append('marina')\n",
    "sw.append('swissotel')\n",
    "sw.append('stamford')\n",
    "sw.append('pan_pacific')\n",
    "stop_words = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2f59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['stem_review'] = df_filtered['stem_review'].apply(remove_stopwords)\n",
    "df_filtered['stem_review'] = df_filtered['stem_review'].apply(remove_non_english_words, valid_words=english_words)\n",
    "df_filtered['tokens'] = df_filtered['stem_review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72b2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precovid = df_filtered[df_filtered['covid'] == 'PreCovid']\n",
    "df_postcovid = df_filtered[df_filtered['covid'] == 'PostCovid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e2940a-4ca9-4462-a9ad-2241a3e56507",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate LDA dictionary and corpus\n",
    "pre_dict = corpora.Dictionary(df_precovid['tokens'])\n",
    "pre_corpus = [pre_dict.doc2bow(text) for text in df_precovid['tokens']]\n",
    "\n",
    "##Generate LDA dictionary and corpus\n",
    "post_dict = corpora.Dictionary(df_postcovid['tokens'])\n",
    "post_corpus = [post_dict.doc2bow(text) for text in df_postcovid['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aadf0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "## Use 5 topics for pre covid corpus\n",
    "pre_ldamodel = lda(pre_corpus, num_topics=5, id2word=pre_dict, passes=15)\n",
    "\n",
    "## Use 5 topics for post covid corpus\n",
    "post_ldamodel = lda(post_corpus, num_topics=5, id2word=pre_dict, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "add24513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pre-COVID\n",
    "topics_pre = pre_ldamodel.show_topics(formatted=False, num_words=20)\n",
    "data_flat_pre = [word for word_list in df_precovid['tokens'] for word in word_list]\n",
    "\n",
    "# For Post-COVID\n",
    "topics_post = post_ldamodel.show_topics(formatted=False)\n",
    "data_flat_post = [word for word_list in df_postcovid['tokens'] for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895116ac-bc13-4eb7-91fc-ef5ddd41229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('tea', 0.047321737),\n",
       "   ('food', 0.046361443),\n",
       "   ('hall', 0.03967458),\n",
       "   ('afternoon', 0.03323972),\n",
       "   ('swiss', 0.026675474),\n",
       "   ('good', 0.021156957),\n",
       "   ('buffet', 0.017647475),\n",
       "   ('drink', 0.017447004),\n",
       "   ('dinner', 0.014735601),\n",
       "   ('free', 0.012463615),\n",
       "   ('sky', 0.012372167),\n",
       "   ('high', 0.01226281),\n",
       "   ('select', 0.011947904),\n",
       "   ('guess', 0.011268003),\n",
       "   ('fresh', 0.010803579),\n",
       "   ('enjoy', 0.010492958),\n",
       "   ('fruit', 0.009401267),\n",
       "   ('birthday', 0.009131017),\n",
       "   ('music', 0.009060685),\n",
       "   ('cake', 0.008373783)]),\n",
       " (1,\n",
       "  [('room', 0.044304807),\n",
       "   ('pool', 0.037158888),\n",
       "   ('view', 0.034097027),\n",
       "   ('hotel', 0.031437326),\n",
       "   ('stay', 0.022299923),\n",
       "   ('floor', 0.018123873),\n",
       "   ('night', 0.01707556),\n",
       "   ('one', 0.013525485),\n",
       "   ('bay', 0.013002982),\n",
       "   ('get', 0.010857099),\n",
       "   ('th', 0.008548654),\n",
       "   ('bed', 0.007822514),\n",
       "   ('go', 0.00753094),\n",
       "   ('like', 0.0073955324),\n",
       "   ('worth', 0.007293336),\n",
       "   ('bathroom', 0.007059812),\n",
       "   ('garden', 0.0070390836),\n",
       "   ('sand', 0.0068007945),\n",
       "   ('nice', 0.0067563076),\n",
       "   ('top', 0.006744592)]),\n",
       " (2,\n",
       "  [('stay', 0.054692116),\n",
       "   ('staff', 0.040597305),\n",
       "   ('hotel', 0.039478257),\n",
       "   ('great', 0.032892004),\n",
       "   ('room', 0.025456963),\n",
       "   ('club', 0.020038046),\n",
       "   ('view', 0.019416036),\n",
       "   ('excel', 0.01831383),\n",
       "   ('love', 0.015265464),\n",
       "   ('help', 0.014214235),\n",
       "   ('us', 0.013930015),\n",
       "   ('best', 0.013162098),\n",
       "   ('thank', 0.012582991),\n",
       "   ('time', 0.012478126),\n",
       "   ('wonder', 0.012151656),\n",
       "   ('recommend', 0.011920772),\n",
       "   ('would', 0.011159703),\n",
       "   ('back', 0.011084462),\n",
       "   ('fantast', 0.010696361),\n",
       "   ('enjoy', 0.010130768)]),\n",
       " (3,\n",
       "  [('hotel', 0.07647686),\n",
       "   ('great', 0.03932695),\n",
       "   ('room', 0.034783486),\n",
       "   ('good', 0.032610476),\n",
       "   ('shop', 0.02898649),\n",
       "   ('stay', 0.0278177),\n",
       "   ('view', 0.019982696),\n",
       "   ('mall', 0.018277999),\n",
       "   ('breakfast', 0.017256929),\n",
       "   ('staff', 0.016616317),\n",
       "   ('walk', 0.01577624),\n",
       "   ('food', 0.015641449),\n",
       "   ('restaur', 0.015460553),\n",
       "   ('nice', 0.015033642),\n",
       "   ('excel', 0.014236148),\n",
       "   ('bay', 0.014054401),\n",
       "   ('well', 0.012598641),\n",
       "   ('clean', 0.011198185),\n",
       "   ('station', 0.010288815),\n",
       "   ('also', 0.009961185)]),\n",
       " (4,\n",
       "  [('check', 0.036481217),\n",
       "   ('room', 0.0342708),\n",
       "   ('hotel', 0.029124524),\n",
       "   ('us', 0.017347943),\n",
       "   ('staff', 0.01593318),\n",
       "   ('time', 0.014416968),\n",
       "   ('book', 0.009860975),\n",
       "   ('stay', 0.009768641),\n",
       "   ('guest', 0.009554139),\n",
       "   ('would', 0.009266332),\n",
       "   ('ask', 0.008983141),\n",
       "   ('wait', 0.008575274),\n",
       "   ('day', 0.008430343),\n",
       "   ('get', 0.007862538),\n",
       "   ('need', 0.007809029),\n",
       "   ('even', 0.0074926475),\n",
       "   ('desk', 0.007324596),\n",
       "   ('one', 0.0071950937),\n",
       "   ('back', 0.0066268737),\n",
       "   ('like', 0.006568131)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032dcca3-dd9f-463c-b61d-33717db88ccf",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20af0093-21f5-4011-b973-90f8f1c20556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3723e9b-3c30-4318-9e85-344a28e837f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in LDA topics output to remove overlap words by choosing highest prob\n",
    "def restruct_topics(topics): \n",
    "    word_prob_dict = {}\n",
    "    for i in range(len(topics)):\n",
    "        topic_num = topics[i][0]\n",
    "        for word, prob in topics[i][1]:\n",
    "            if word in word_prob_dict:\n",
    "                word_prob_dict[word].append((topic_num, prob))\n",
    "            else:\n",
    "                ls = [(topic_num, prob)]\n",
    "                word_prob_dict[word] = ls\n",
    "    new_dict = {}\n",
    "    for word in word_prob_dict:\n",
    "        topic, highest_prob = max(word_prob_dict[word], key = lambda x: x[1])\n",
    "        if topic in new_dict:\n",
    "            new_dict[topic].append(word)\n",
    "        else:\n",
    "            ls = [word]\n",
    "            new_dict[topic] = ls\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "288cbd19-53f8-4de9-88e6-19d368532112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length topic 0: 19\n",
      "length topic 3: 14\n",
      "length topic 1: 16\n",
      "length topic 2: 13\n",
      "length topic 4: 11\n"
     ]
    }
   ],
   "source": [
    "new_dict = restruct_topics(topics_pre)\n",
    "for x in new_dict:\n",
    "    print(f'length topic {x}: {len(new_dict[x])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88aae961-763d-4c94-95cf-d895a6239944",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc60de21-2af6-41fb-a6fd-c35006e4f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in the dataframe and appends to each row (aspect, review) pair(s)\n",
    "def dep_parse(data, new_dict):\n",
    "    data['aspect_sentiment'] = np.empty((len(data), 0)).tolist()\n",
    "    for i in range(len(data)):\n",
    "        sentence = data['combined_review'][i]\n",
    "        doc = nlp(sentence)\n",
    "        aspect_sentiment = []\n",
    "        for word in doc:\n",
    "            cond = False\n",
    "            for x in new_dict.values():\n",
    "                if word.text in x:\n",
    "                    cond = True\n",
    "                    break\n",
    "            if not cond:\n",
    "                continue\n",
    "            if word.pos_ == 'NOUN': \n",
    "                for j in word.lefts:\n",
    "                    #print(j, word, j.dep_, j.pos_)\n",
    "                    if j.dep_ == 'amod' and j.pos_ == 'ADJ':\n",
    "                        tup = [word, j, list(new_dict.values()).index(x)]\n",
    "                        #print(tup)\n",
    "                        aspect_sentiment.append(tup)\n",
    "                    for k in j.lefts:\n",
    "                        if k.dep_ == 'advmod':\n",
    "                            #print(word, j ,k)\n",
    "                            tup = [word, k.text + ' ' + j.text, list(new_dict.values()).index(x)]\n",
    "                            aspect_sentiment.append(tup)\n",
    "                            if (word, j) in aspect_sentiment:\n",
    "                                aspect_sentiment.remove([word, j, list(new_dict.values()).index(x)])\n",
    "        data['aspect_sentiment'][i] = aspect_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1798de87-51d3-43f7-b6f3-893bfc8c1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86dd31bf-8d7b-414e-8e28-6c7048c2ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_parse(df_filtered, new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df65aa72-fe84-466e-b9b4-200f95cb4c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       []\n",
       "1            [[hotel, Best, 1], [breakfast, delicious, 1]]\n",
       "2                                        [[stay, nice, 3]]\n",
       "3                                       [[desk, front, 4]]\n",
       "4                                        [[time, next, 4]]\n",
       "                               ...                        \n",
       "35617    [[stay, recent, 3], [stay, most recent, 3], [h...\n",
       "35618    [[view, sensational, 2], [floor, 40th, 2], [vi...\n",
       "35619    [[view, great, 2], [room, decent, 2], [room, l...\n",
       "35620                               [[hotel, Ordinary, 1]]\n",
       "35621    [[floor, 57th, 2], [day, first, 4], [room, sma...\n",
       "Name: aspect_sentiment, Length: 35622, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['aspect_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c44931a6-e6fe-4228-819b-fa6cf8094fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traveller_username</th>\n",
       "      <th>date</th>\n",
       "      <th>covid</th>\n",
       "      <th>star</th>\n",
       "      <th>rating</th>\n",
       "      <th>aspect_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carolyn H</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>srquarry</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[hotel, Best, 1], [breakfast, delicious, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria del Mar M</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[stay, nice, 3]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  traveller_username        date      covid  star  rating  \\\n",
       "0          Carolyn H  2023-09-01  PostCovid     5     5.0   \n",
       "1           srquarry  2023-03-01  PostCovid     5     NaN   \n",
       "2    Maria del Mar M  2023-08-01  PostCovid     5     5.0   \n",
       "\n",
       "                                aspect_sentiment  \n",
       "0                                             []  \n",
       "1  [[hotel, Best, 1], [breakfast, delicious, 1]]  \n",
       "2                              [[stay, nice, 3]]  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df_filtered[[\"traveller_username\", \"date\", \"covid\", \"star\", \"rating\", \"aspect_sentiment\"]]\n",
    "df_subset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a64ee-12ef-4219-ae2f-80789338c625",
   "metadata": {},
   "source": [
    "# Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9472696-c518-44a6-ad08-25bee7bc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "73ca8d51-4671-49e9-843e-dbca98588b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_sentiment_column = df_subset['aspect_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef6c04-3705-433a-98e9-5afbdb156256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Draft Function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f019160d-a927-44a3-a533-1f040c26c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aspect_count(row):\n",
    "    counts = {}\n",
    "    \n",
    "    for aspect_sentiment in row:\n",
    "        if aspect_sentiment:  # Check if the list is not empty\n",
    "            topic = aspect_sentiment[2]\n",
    "            \n",
    "            column_name = f'topic_{topic}'\n",
    "            \n",
    "            # Count occurrences of each topic\n",
    "            count_column_name = f'count_{column_name}'\n",
    "            counts[count_column_name] = counts.get(count_column_name, 0) + 1\n",
    "            #print(counts[count_column_name])\n",
    "    return pd.Series({**counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f8ccb6a6-4605-4fa4-93ac-01df18364483",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = [[\"hotel\", \"Great\", 1],\n",
    "        [\"hotel\", \"Excellent\", 1],\n",
    "        [\"room\", \"nice\", 2],\n",
    "        [\"room\", 'very nice', 2],\n",
    "        [\"staff\", \"helpful\", 2],\n",
    "        [\"staff\", 'extremely helpful', 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "927ed4b2-e461-4839-b4c5-48401b8de735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_topic_1    2\n",
       "count_topic_2    3\n",
       "count_topic_3    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_aspect_count(row1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1015184-5afc-4154-8ecb-c2250148d51b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Draft Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a8ed1806-a452-4b22-bc10-9bfafe41b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate TextBlob score for each aspect-adjective pair\n",
    "def calculate_textblob_score_and_count(row):\n",
    "    scores = {}\n",
    "    counts = {}\n",
    "    \n",
    "    for aspect_sentiment in row:\n",
    "        if aspect_sentiment:  # Check if the list is not empty\n",
    "            aspect = aspect_sentiment[0]\n",
    "            adjective = aspect_sentiment[1]\n",
    "            topic = aspect_sentiment[2]\n",
    "            \n",
    "            # Concatenate aspect and adjective\n",
    "            text_to_analyze = f\"{aspect}, {adjective}\"\n",
    "            \n",
    "            # Calculate TextBlob score\n",
    "            score = TextBlob(text_to_analyze).sentiment.polarity\n",
    "            \n",
    "            \n",
    "            column_name = f'topic_{topic}'\n",
    "            \n",
    "            # Assign the score to the corresponding topic column\n",
    "            scores[column_name] = score\n",
    "            \n",
    "            # Count occurrences of each topic\n",
    "            count_column_name = f'count_{column_name}'\n",
    "            counts[count_column_name] = counts.get(count_column_name, 0) + 1\n",
    "    \n",
    "    return pd.Series({**scores, **counts})\n",
    "    \n",
    "    #return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd4630cc-6f48-4bd4-870b-27180efec5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[hotel, Great, 1],\n",
       " [hotel, Excellent, 1],\n",
       " [room, nice, 2],\n",
       " [room, 'very nice', 2],\n",
       " [staff, helpful, 3],\n",
       " [staff, 'extremely helpful', 3]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_sentiment_column[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c70a2de1-779e-49a2-9f55-3948863301ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>count_topic_1</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>count_topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>count_topic_4</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>count_topic_2</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>count_topic_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.85</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_1  count_topic_1  topic_3  count_topic_3  topic_4  count_topic_4  \\\n",
       "0      NaN            NaN      NaN            NaN      NaN            NaN   \n",
       "1     1.00            2.0      NaN            NaN      NaN            NaN   \n",
       "2      NaN            NaN      0.6            1.0      NaN            NaN   \n",
       "3      NaN            NaN      NaN            NaN     0.00            1.0   \n",
       "4      NaN            NaN      NaN            NaN     0.00            1.0   \n",
       "5     0.85            2.0      NaN            NaN      NaN            NaN   \n",
       "6      NaN            NaN      NaN            NaN      NaN            NaN   \n",
       "7      NaN            NaN      NaN            NaN     0.25            1.0   \n",
       "8      NaN            NaN      0.8            1.0      NaN            NaN   \n",
       "9      NaN            NaN      NaN            NaN      NaN            NaN   \n",
       "\n",
       "   topic_2  count_topic_2  topic_0  count_topic_0  \n",
       "0      NaN            NaN      NaN            NaN  \n",
       "1      NaN            NaN      NaN            NaN  \n",
       "2      NaN            NaN      NaN            NaN  \n",
       "3      NaN            NaN      NaN            NaN  \n",
       "4      NaN            NaN      NaN            NaN  \n",
       "5      0.4            2.0      NaN            NaN  \n",
       "6      NaN            NaN      NaN            NaN  \n",
       "7      NaN            NaN      NaN            NaN  \n",
       "8      0.7            1.0     0.16            1.0  \n",
       "9      0.8            1.0      NaN            NaN  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function on subset of data\n",
    "aspect_sentiment_column[:10].apply(calculate_textblob_score_and_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e260f05-988a-4483-a8e2-8576983eaeab",
   "metadata": {},
   "source": [
    "## Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e3349b1c-aa68-40b4-b87c-1ffcfe04b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate mean TextBlob polarity for each topic\n",
    "def calculate_mean_textblob_polarity(row):\n",
    "    scores = {}\n",
    "    counts = {}\n",
    "    \n",
    "    for aspect_sentiment in row:\n",
    "        if aspect_sentiment:  # Check if the list is not empty\n",
    "            aspect = aspect_sentiment[0]\n",
    "            adjective = aspect_sentiment[1]\n",
    "            topic = aspect_sentiment[2]\n",
    "            \n",
    "            # Concatenate aspect and adjective\n",
    "            text_to_analyze = f\"{aspect} {adjective}\"\n",
    "            \n",
    "            # Calculate TextBlob polarity\n",
    "            polarity = TextBlob(text_to_analyze).sentiment.polarity\n",
    "            \n",
    "            # Accumulate polarity values of each aspect within a topic\n",
    "            column_name = f'topic_{topic}'\n",
    "            scores[column_name] = scores.get(column_name, 0) + polarity # add polarity to existing polarity (if have)\n",
    "            # if a topic occurence is more than once, scores[column_name] will be the summed polarity\n",
    "            \n",
    "            # Count occurrences of each aspect within a topic\n",
    "            count_column_name = f'count_{column_name}'\n",
    "            counts[count_column_name] = counts.get(count_column_name, 0) + 1\n",
    "    \n",
    "    # Calculate mean polarity for each topic\n",
    "    for count_column_name, topic_count in counts.items():\n",
    "        #print(counts.items())\n",
    "        column_name = count_column_name.replace('count_', '')\n",
    "        mean_polarity = scores[column_name] / counts[count_column_name]\n",
    "        scores[column_name] = mean_polarity # replace summed polarity with mean polarity\n",
    "\n",
    "    return pd.Series({**counts, **scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "92e01462-3013-4c70-ae79-ee5b4eb3f146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_topic_1</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>count_topic_3</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>count_topic_4</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>count_topic_2</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>count_topic_0</th>\n",
       "      <th>topic_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_topic_1  topic_1  count_topic_3  topic_3  count_topic_4  topic_4  \\\n",
       "0            NaN      NaN            NaN      NaN            NaN      NaN   \n",
       "1            2.0     1.00            NaN      NaN            NaN      NaN   \n",
       "2            NaN      NaN            1.0      0.6            NaN      NaN   \n",
       "3            NaN      NaN            NaN      NaN            1.0     0.00   \n",
       "4            NaN      NaN            NaN      NaN            1.0     0.00   \n",
       "5            2.0     0.85            NaN      NaN            NaN      NaN   \n",
       "6            NaN      NaN            NaN      NaN            NaN      NaN   \n",
       "7            NaN      NaN            NaN      NaN            1.0     0.25   \n",
       "8            NaN      NaN            1.0      0.8            NaN      NaN   \n",
       "9            NaN      NaN            NaN      NaN            NaN      NaN   \n",
       "\n",
       "   count_topic_2  topic_2  count_topic_0  topic_0  \n",
       "0            NaN      NaN            NaN      NaN  \n",
       "1            NaN      NaN            NaN      NaN  \n",
       "2            NaN      NaN            NaN      NaN  \n",
       "3            NaN      NaN            NaN      NaN  \n",
       "4            NaN      NaN            NaN      NaN  \n",
       "5            2.0      0.5            NaN      NaN  \n",
       "6            NaN      NaN            NaN      NaN  \n",
       "7            NaN      NaN            NaN      NaN  \n",
       "8            1.0      0.7            1.0     0.16  \n",
       "9            1.0      0.8            NaN      NaN  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_sentiment_column[:10].apply(calculate_mean_textblob_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f018beac-4612-4964-8e33-7f9dfad7c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traveller_username</th>\n",
       "      <th>date</th>\n",
       "      <th>covid</th>\n",
       "      <th>star</th>\n",
       "      <th>rating</th>\n",
       "      <th>aspect_sentiment</th>\n",
       "      <th>count_topic_1</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>count_topic_3</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>count_topic_4</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>count_topic_2</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>count_topic_0</th>\n",
       "      <th>topic_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carolyn H</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>srquarry</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[hotel, Best, 1], [breakfast, delicious, 1]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria del Mar M</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[stay, nice, 3]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARIA DEL MAR M</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[desk, front, 4]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alanis K</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[time, next, 4]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35617</th>\n",
       "      <td>Bluecann</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>PreCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[stay, recent, 3], [stay, most recent, 3], [h...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35618</th>\n",
       "      <td>Rick J</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>PreCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[view, sensational, 2], [floor, 40th, 2], [vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35619</th>\n",
       "      <td>BabaYagaL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>PreCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[view, great, 2], [room, decent, 2], [room, l...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35620</th>\n",
       "      <td>Howard J</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>PreCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[hotel, Ordinary, 1]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35621</th>\n",
       "      <td>bluedusk</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>PreCovid</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[floor, 57th, 2], [day, first, 4], [room, sma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35622 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      traveller_username        date      covid  star  rating  \\\n",
       "0              Carolyn H  2023-09-01  PostCovid     5     5.0   \n",
       "1               srquarry  2023-03-01  PostCovid     5     NaN   \n",
       "2        Maria del Mar M  2023-08-01  PostCovid     5     5.0   \n",
       "3        MARIA DEL MAR M  2023-08-01  PostCovid     5     5.0   \n",
       "4               Alanis K  2023-09-01  PostCovid     5     5.0   \n",
       "...                  ...         ...        ...   ...     ...   \n",
       "35617           Bluecann  2015-01-01   PreCovid     5     2.0   \n",
       "35618             Rick J  2015-01-01   PreCovid     5     5.0   \n",
       "35619          BabaYagaL  2015-01-01   PreCovid     5     4.0   \n",
       "35620           Howard J  2015-01-01   PreCovid     5     1.0   \n",
       "35621           bluedusk  2015-01-01   PreCovid     5     2.0   \n",
       "\n",
       "                                        aspect_sentiment  count_topic_1  \\\n",
       "0                                                     []            NaN   \n",
       "1          [[hotel, Best, 1], [breakfast, delicious, 1]]            2.0   \n",
       "2                                      [[stay, nice, 3]]            NaN   \n",
       "3                                     [[desk, front, 4]]            NaN   \n",
       "4                                      [[time, next, 4]]            NaN   \n",
       "...                                                  ...            ...   \n",
       "35617  [[stay, recent, 3], [stay, most recent, 3], [h...            1.0   \n",
       "35618  [[view, sensational, 2], [floor, 40th, 2], [vi...            NaN   \n",
       "35619  [[view, great, 2], [room, decent, 2], [room, l...            1.0   \n",
       "35620                             [[hotel, Ordinary, 1]]            1.0   \n",
       "35621  [[floor, 57th, 2], [day, first, 4], [room, sma...            NaN   \n",
       "\n",
       "       topic_1  count_topic_3  topic_3  count_topic_4  topic_4  count_topic_2  \\\n",
       "0          NaN            NaN      NaN            NaN      NaN            NaN   \n",
       "1         1.00            NaN      NaN            NaN      NaN            NaN   \n",
       "2          NaN            1.0    0.600            NaN      NaN            NaN   \n",
       "3          NaN            NaN      NaN            1.0     0.00            NaN   \n",
       "4          NaN            NaN      NaN            1.0     0.00            NaN   \n",
       "...        ...            ...      ...            ...      ...            ...   \n",
       "35617     0.00            2.0    0.125            1.0    -0.30            NaN   \n",
       "35618      NaN            NaN      NaN            NaN      NaN            3.0   \n",
       "35619     0.00            NaN      NaN            NaN      NaN            6.0   \n",
       "35620    -0.25            NaN      NaN            NaN      NaN            NaN   \n",
       "35621      NaN            NaN      NaN            1.0     0.25            2.0   \n",
       "\n",
       "        topic_2  count_topic_0  topic_0  \n",
       "0           NaN            NaN      NaN  \n",
       "1           NaN            NaN      NaN  \n",
       "2           NaN            NaN      NaN  \n",
       "3           NaN            NaN      NaN  \n",
       "4           NaN            NaN      NaN  \n",
       "...         ...            ...      ...  \n",
       "35617       NaN            NaN      NaN  \n",
       "35618  0.455556            NaN      NaN  \n",
       "35619  0.196825            NaN      NaN  \n",
       "35620       NaN            NaN      NaN  \n",
       "35621 -0.125000            NaN      NaN  \n",
       "\n",
       "[35622 rows x 16 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = df_subset['aspect_sentiment'].apply(calculate_mean_textblob_polarity)\n",
    "\n",
    "# Concatenate the result DataFrame with df_subset\n",
    "df_subset_with_scores = pd.concat([df_subset, result_df], axis=1)\n",
    "df_subset_with_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bt4222_hotels]",
   "language": "python",
   "name": "conda-env-bt4222_hotels-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
