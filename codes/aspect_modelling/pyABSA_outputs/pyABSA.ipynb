{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691fcd48-297e-435f-a80e-f7290de2873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b0125-77a0-4965-8232-034c74004bbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802ebbd7-1843-4484-9ce7-dff350ce45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify these list if needed (eg. if you want to load only 1 csv from star3, delete other csvs in star3 list)\n",
    "star3 = ['cleaned_ibis-sg-bencoolen.csv','cleaned_hotel-boss.csv','cleaned_hotel-G.csv',\n",
    "           'cleaned_village-hotel-albert-court-by-far-east-hospitality.csv',\n",
    "           'cleaned_holiday-inn-express-clarke-quay.csv']\n",
    "star4 = ['cleaned_village-hotel-changi-by-far-east-hospitality.csv',\n",
    "         'cleaned_park-regis.csv', 'cleaned_grand-mercure-sg-roxy.csv',\n",
    "         'cleaned_paradox-sg-merchant-court.csv','cleaned_crowne-plaza.csv']\n",
    "star5 = ['cleaned_fullerton.csv', 'cleaned_parkroyal-collection-marina-bay.csv', 'cleaned_pan-pacific.csv',\n",
    "          'cleaned_mbs_total.csv', 'cleaned_swissotel-the-stamford.csv']\n",
    "\n",
    "RAW_FOLDER = \"../../../data/processed/\"\n",
    "\n",
    "def combine_csv_to_dataframe(file_names, all_star = False, filterDate = True):\n",
    "    \"\"\"\n",
    "    Combine multiple CSV files into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_names (list): List of CSV file names. \n",
    "    all_star (bool): whether or not to load all the hotels (False if only want to load 1 type of hotel star). \n",
    "    filterData (bool): whether or not to remove all data dated before 2015\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_interim_path = RAW_FOLDER + file_name\n",
    "        file_path = file_interim_path\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            if all_star:\n",
    "                if file_name in star3:\n",
    "                    df[\"star\"] = 3\n",
    "                elif file_name in star4:\n",
    "                    df[\"star\"] = 4\n",
    "                else:\n",
    "                    df[\"star\"] = 5\n",
    "            #print(f\"Length of {file_name} is {len(df)}\")\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            #print(len(combined_df))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Empty or invalid CSV file: {file_name}\")\n",
    "            \n",
    "    combined_df = combined_df[combined_df.year > 2000]\n",
    "                    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1ddb70-3224-4b63-8b40-4d145bf4822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68292 entries, 0 to 68291\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Unnamed: 0                             68292 non-null  int64  \n",
      " 1   traveller_username                     68292 non-null  object \n",
      " 2   review_title                           68253 non-null  object \n",
      " 3   review_text                            68292 non-null  object \n",
      " 4   travel_type                            31354 non-null  object \n",
      " 5   traveller_country_origin               51724 non-null  object \n",
      " 6   traveller_total_contributions          68103 non-null  object \n",
      " 7   traveller_total_helpful_contributions  54090 non-null  float64\n",
      " 8   rating                                 54837 non-null  float64\n",
      " 9   valid_rating                           68292 non-null  bool   \n",
      " 10  label                                  54837 non-null  object \n",
      " 11  cleaned_review                         68292 non-null  object \n",
      " 12  combined_review                        68292 non-null  object \n",
      " 13  date                                   68292 non-null  object \n",
      " 14  covid                                  68292 non-null  object \n",
      " 15  year                                   68292 non-null  int64  \n",
      " 16  stem_review                            68292 non-null  object \n",
      " 17  lem_review                             68292 non-null  object \n",
      " 18  star                                   68292 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(3), object(13)\n",
      "memory usage: 9.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>traveller_username</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>travel_type</th>\n",
       "      <th>traveller_country_origin</th>\n",
       "      <th>traveller_total_contributions</th>\n",
       "      <th>traveller_total_helpful_contributions</th>\n",
       "      <th>rating</th>\n",
       "      <th>valid_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>combined_review</th>\n",
       "      <th>date</th>\n",
       "      <th>covid</th>\n",
       "      <th>year</th>\n",
       "      <th>stem_review</th>\n",
       "      <th>lem_review</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Love_Life_Sydney</td>\n",
       "      <td>Clean and comfortable</td>\n",
       "      <td>Hotel rooms in Singapore are so expensive so t...</td>\n",
       "      <td>Trip type: Travelled as a couple</td>\n",
       "      <td>Sydney, Australia</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>clean comfortable hotel rooms singapore expens...</td>\n",
       "      <td>Clean and comfortable Hotel rooms in Singapore...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2023</td>\n",
       "      <td>clean comfort hotel room singapor expens find ...</td>\n",
       "      <td>clean comfortable hotel room singapore expensi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bilal S</td>\n",
       "      <td>Good hotel, great location</td>\n",
       "      <td>This is a great place! Location is great but t...</td>\n",
       "      <td>Trip type: Travelled with family</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>Good hotel, great location  This is a great pl...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2023</td>\n",
       "      <td>good hotel great locat great place locat great...</td>\n",
       "      <td>good hotel great location great place location...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anthony Fernando</td>\n",
       "      <td>Good place for a decent price.</td>\n",
       "      <td>Good place good price  Easy access to the city...</td>\n",
       "      <td>Trip type: Travelled with friends</td>\n",
       "      <td>Dubai, United Arab Emirates</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>Good place for a decent price. Good place good...</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2022</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>good place decent price good place good price ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mjkc204</td>\n",
       "      <td>Great Location and great staff.</td>\n",
       "      <td>The IBIS was a neat and tidy hotel in line wit...</td>\n",
       "      <td>Trip type: Travelled solo</td>\n",
       "      <td>Ellenbrook, Australia</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>Great Location and great staff. The IBIS was a...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2023</td>\n",
       "      <td>great locat great staff ibi neat tidi hotel li...</td>\n",
       "      <td>great location great staff ibis neat tidy hote...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aung Nanda</td>\n",
       "      <td>Good for budget stay.</td>\n",
       "      <td>I stayed there for 7 days. It was a nice locat...</td>\n",
       "      <td>Trip type: Travelled on business</td>\n",
       "      <td>Dubai, United Arab Emirates</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good budget stay stayed days nice location sev...</td>\n",
       "      <td>Good for budget stay. I stayed there for 7 day...</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>PostCovid</td>\n",
       "      <td>2022</td>\n",
       "      <td>good budget stay stay day nice locat seven ele...</td>\n",
       "      <td>good budget stay stay day nice location seven ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 traveller_username                     review_title  \\\n",
       "0           0   Love_Life_Sydney            Clean and comfortable   \n",
       "1           1            Bilal S      Good hotel, great location    \n",
       "2           2   Anthony Fernando   Good place for a decent price.   \n",
       "3           3            Mjkc204  Great Location and great staff.   \n",
       "4           4         Aung Nanda            Good for budget stay.   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  Hotel rooms in Singapore are so expensive so t...   \n",
       "1  This is a great place! Location is great but t...   \n",
       "2  Good place good price  Easy access to the city...   \n",
       "3  The IBIS was a neat and tidy hotel in line wit...   \n",
       "4  I stayed there for 7 days. It was a nice locat...   \n",
       "\n",
       "                         travel_type     traveller_country_origin  \\\n",
       "0   Trip type: Travelled as a couple            Sydney, Australia   \n",
       "1   Trip type: Travelled with family               Houston, Texas   \n",
       "2  Trip type: Travelled with friends  Dubai, United Arab Emirates   \n",
       "3          Trip type: Travelled solo        Ellenbrook, Australia   \n",
       "4   Trip type: Travelled on business  Dubai, United Arab Emirates   \n",
       "\n",
       "  traveller_total_contributions  traveller_total_helpful_contributions  \\\n",
       "0                        2302.0                                  871.0   \n",
       "1                           4.0                                    NaN   \n",
       "2                          39.0                                   38.0   \n",
       "3                          37.0                                   19.0   \n",
       "4                           3.0                                    4.0   \n",
       "\n",
       "   rating  valid_rating     label  \\\n",
       "0     4.0          True  Positive   \n",
       "1     5.0          True  Positive   \n",
       "2     5.0          True  Positive   \n",
       "3     5.0          True  Positive   \n",
       "4     4.0          True  Positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  clean comfortable hotel rooms singapore expens...   \n",
       "1  good hotel great location great place location...   \n",
       "2  good place decent price good place good price ...   \n",
       "3  great location great staff ibis neat tidy hote...   \n",
       "4  good budget stay stayed days nice location sev...   \n",
       "\n",
       "                                     combined_review        date      covid  \\\n",
       "0  Clean and comfortable Hotel rooms in Singapore...  2023-08-01  PostCovid   \n",
       "1  Good hotel, great location  This is a great pl...  2023-08-01  PostCovid   \n",
       "2  Good place for a decent price. Good place good...  2022-10-01  PostCovid   \n",
       "3  Great Location and great staff. The IBIS was a...  2023-08-01  PostCovid   \n",
       "4  Good for budget stay. I stayed there for 7 day...  2022-08-01  PostCovid   \n",
       "\n",
       "   year                                        stem_review  \\\n",
       "0  2023  clean comfort hotel room singapor expens find ...   \n",
       "1  2023  good hotel great locat great place locat great...   \n",
       "2  2022  good place decent price good place good price ...   \n",
       "3  2023  great locat great staff ibi neat tidi hotel li...   \n",
       "4  2022  good budget stay stay day nice locat seven ele...   \n",
       "\n",
       "                                          lem_review  star  \n",
       "0  clean comfortable hotel room singapore expensi...     3  \n",
       "1  good hotel great location great place location...     3  \n",
       "2  good place decent price good place good price ...     3  \n",
       "3  great location great staff ibis neat tidy hote...     3  \n",
       "4  good budget stay stay day nice location seven ...     3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combine_csv_to_dataframe(star3+star4+star5, all_star = True, filterDate = True)\n",
    "#data[['traveller_username','date','travel_type','traveller_total_contributions','traveller_total_helpful_contributions','review_title','review_text','rating']].head(5)\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535cd94b-454a-4fdc-9012-f4a3f6d373ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2017    12243\n",
       "2016    11747\n",
       "2018    10700\n",
       "2019    10537\n",
       "2015    10111\n",
       "2022     4126\n",
       "2023     3719\n",
       "2021     2675\n",
       "2020     2434\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2af4e13-2109-4b38-bdc1-19221d500580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star\n",
       "5    35622\n",
       "4    18600\n",
       "3    14070\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.star.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e203230f-027a-40b4-bbba-29f27029b0d0",
   "metadata": {},
   "source": [
    "# Pre-Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b88f0b2-12f7-40ee-9365-355766330907",
   "metadata": {},
   "outputs": [],
   "source": [
    "precovid = data[data.covid == \"PreCovid\"]\n",
    "precovid_3star = precovid[precovid.star==3]\n",
    "precovid_4star = precovid[precovid.star==4]\n",
    "precovid_5star = precovid[precovid.star==5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f06d2-97e1-4a8b-acfe-2ef197e11886",
   "metadata": {},
   "source": [
    "# Post-Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61bef23-7628-456c-8d41-f4447f07a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcovid = data[data.covid == \"PostCovid\"]\n",
    "postcovid_3star = postcovid[postcovid.star==3]\n",
    "postcovid_4star = postcovid[postcovid.star==4]\n",
    "postcovid_5star = postcovid[postcovid.star==5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3d296",
   "metadata": {},
   "source": [
    "## Just Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7887b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_star = data[data.star == 3]\n",
    "four_star = data[data.star == 4]\n",
    "five_star = data[data.star == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a26ef-19c4-4515-9fc6-d923c8f502bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# pyABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aed9a13-9995-41a3-aefd-4ecb34e59dec",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "[2023-11-12 21:40:22] (2.3.4) \u001b[31mPyABSA(2.3.4): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.x versions, e.g., pip install pyabsa<2.0 -U\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING: When you fails to load a checkpoint, e.g., Unexpected key(s),\n",
      "Try to downgrade transformers<=4.29.0.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\multiprocessing\\pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from pyabsa import (\n",
    "    ATEPCCheckpointManager,\n",
    "    AspectTermExtraction as ATEPC,\n",
    "    DeviceTypeOption,\n",
    "    available_checkpoints,\n",
    ")\n",
    "from pyabsa import TaskCodeOption\n",
    "\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dca1af-74ff-4dfb-9ab2-6dc8bed85770",
   "metadata": {},
   "source": [
    "## Define Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7503520b-e197-42d3-b416-a8f070beb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_map = available_checkpoints(\n",
    "    TaskCodeOption.Aspect_Polarity_Classification, show_ckpts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fa1ee-3267-4e9d-bdd7-e1f632c9d157",
   "metadata": {},
   "source": [
    "## Define aspect extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "446b3cdc-b685-47e2-910b-d4ad80dcdea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-12 21:40:39] (2.3.4) \u001b[32mDownloading checkpoint:english \u001b[0m\n",
      "[2023-11-12 21:40:39] (2.3.4) \u001b[31mNotice: The pretrained model are used for testing, it is recommended to train the model on your own custom datasets\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint: 579MB [02:42,  3.56MB/s]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find zipped checkpoint: ./checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43.zip, unzipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "[2023-11-12 21:43:27] (2.3.4) \u001b[33mIf the auto-downloading failed, please download it via browser: https://huggingface.co/spaces/yangheng/PyABSA/resolve/main/checkpoints/English/ATEPC/fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43.zip \u001b[0m\n",
      "[2023-11-12 21:43:27] (2.3.4) Load aspect extractor from checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\n",
      "[2023-11-12 21:43:27] (2.3.4) config: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\\fast_lcf_atepc.config\n",
      "[2023-11-12 21:43:27] (2.3.4) state_dict: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\\fast_lcf_atepc.state_dict\n",
      "[2023-11-12 21:43:27] (2.3.4) model: None\n",
      "[2023-11-12 21:43:27] (2.3.4) tokenizer: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\\fast_lcf_atepc.tokenizer\n",
      "[2023-11-12 21:43:27] (2.3.4) Set Model Device: cpu\n",
      "[2023-11-12 21:43:27] (2.3.4) Device Name: Unknown\n"
     ]
    }
   ],
   "source": [
    "aspect_extractor = ATEPC.AspectExtractor('english', auto_device=DeviceTypeOption.AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d91a6-0a81-4730-97ff-f2c9411dec8e",
   "metadata": {},
   "source": [
    "# Batch Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2614e",
   "metadata": {},
   "source": [
    "## 3-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c04d717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|█| 14070/14070 [01:07<00:00, 208.22it/\n",
      "extracting aspect terms:   1%|▏             | 1/110 [01:51<3:23:17, 111.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m atepc_result \u001b[38;5;241m=\u001b[39m aspect_extractor\u001b[38;5;241m.\u001b[39mbatch_predict(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mlist\u001b[39m(three_star[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstem_review\u001b[39m\u001b[38;5;124m\"\u001b[39m]),  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     save_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     print_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# print the result\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     pred_sentiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Predict the sentiment of extracted aspect terms\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:307\u001b[0m, in \u001b[0;36mAspectExtractor.batch_predict\u001b[1;34m(self, target_file, save_result, print_result, pred_sentiment, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run inference using examples list or inference dataset path (list)!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m     )\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_file:\n\u001b[1;32m--> 307\u001b[0m     extraction_res, sentence_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract(target_file)\n\u001b[0;32m    308\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextraction_res\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extraction_res\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred_sentiment:\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:452\u001b[0m, in \u001b[0;36mAspectExtractor._extract\u001b[1;34m(self, examples)\u001b[0m\n\u001b[0;32m    450\u001b[0m l_mask \u001b[38;5;241m=\u001b[39m l_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 452\u001b[0m     ate_logits, apc_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    453\u001b[0m         input_ids_spc,\n\u001b[0;32m    454\u001b[0m         token_type_ids\u001b[38;5;241m=\u001b[39msegment_ids,\n\u001b[0;32m    455\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39minput_mask,\n\u001b[0;32m    456\u001b[0m         labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    457\u001b[0m         polarity\u001b[38;5;241m=\u001b[39mpolarity,\n\u001b[0;32m    458\u001b[0m         valid_ids\u001b[38;5;241m=\u001b[39mvalid_ids,\n\u001b[0;32m    459\u001b[0m         attention_mask_label\u001b[38;5;241m=\u001b[39ml_mask,\n\u001b[0;32m    460\u001b[0m     )\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_bert_spc:\n\u001b[0;32m    462\u001b[0m     label_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_batch_token_labels_bert_base_indices(\n\u001b[0;32m    463\u001b[0m         label_ids\n\u001b[0;32m    464\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\models\\__lcf__\\fast_lcf_atepc.py:75\u001b[0m, in \u001b[0;36mFAST_LCF_ATEPC.forward\u001b[1;34m(self, input_ids_spc, token_type_ids, attention_mask, labels, polarity, valid_ids, attention_mask_label, lcf_cdm_vec, lcf_cdw_vec)\u001b[0m\n\u001b[0;32m     73\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_ids_for_local_context_extractor(input_ids_spc)\n\u001b[0;32m     74\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_token_labels_bert_base_indices(labels)\n\u001b[1;32m---> 75\u001b[0m     global_context_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert4global(\n\u001b[0;32m     76\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[0;32m     77\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     global_context_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert4global(\n\u001b[0;32m     80\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids_spc, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[0;32m     81\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1074\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1064\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m   1066\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1067\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1068\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1072\u001b[0m )\n\u001b[1;32m-> 1074\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1075\u001b[0m     embedding_output,\n\u001b[0;32m   1076\u001b[0m     attention_mask,\n\u001b[0;32m   1077\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1078\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1079\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1080\u001b[0m )\n\u001b[0;32m   1081\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:514\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[0;32m    504\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    505\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    506\u001b[0m         next_kv,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         output_attentions,\n\u001b[0;32m    512\u001b[0m     )\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    515\u001b[0m         next_kv,\n\u001b[0;32m    516\u001b[0m         attention_mask,\n\u001b[0;32m    517\u001b[0m         query_states\u001b[38;5;241m=\u001b[39mquery_states,\n\u001b[0;32m    518\u001b[0m         relative_pos\u001b[38;5;241m=\u001b[39mrelative_pos,\n\u001b[0;32m    519\u001b[0m         rel_embeddings\u001b[38;5;241m=\u001b[39mrel_embeddings,\n\u001b[0;32m    520\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    524\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:362\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[1;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    355\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    360\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m ):\n\u001b[1;32m--> 362\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    363\u001b[0m         hidden_states,\n\u001b[0;32m    364\u001b[0m         attention_mask,\n\u001b[0;32m    365\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    366\u001b[0m         query_states\u001b[38;5;241m=\u001b[39mquery_states,\n\u001b[0;32m    367\u001b[0m         relative_pos\u001b[38;5;241m=\u001b[39mrelative_pos,\n\u001b[0;32m    368\u001b[0m         rel_embeddings\u001b[38;5;241m=\u001b[39mrel_embeddings,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    371\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:293\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    286\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    292\u001b[0m ):\n\u001b[1;32m--> 293\u001b[0m     self_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    294\u001b[0m         hidden_states,\n\u001b[0;32m    295\u001b[0m         attention_mask,\n\u001b[0;32m    296\u001b[0m         output_attentions,\n\u001b[0;32m    297\u001b[0m         query_states\u001b[38;5;241m=\u001b[39mquery_states,\n\u001b[0;32m    298\u001b[0m         relative_pos\u001b[38;5;241m=\u001b[39mrelative_pos,\n\u001b[0;32m    299\u001b[0m         rel_embeddings\u001b[38;5;241m=\u001b[39mrel_embeddings,\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    302\u001b[0m         self_output, att_matrix \u001b[38;5;241m=\u001b[39m self_output\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:733\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    728\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m attention_scores\u001b[38;5;241m.\u001b[39mview(\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, attention_scores\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), attention_scores\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    730\u001b[0m )\n\u001b[0;32m    732\u001b[0m \u001b[38;5;66;03m# bsz x height x length x dimension\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m XSoftmax\u001b[38;5;241m.\u001b[39mapply(attention_scores, attention_mask, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    734\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n\u001b[0;32m    735\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(\n\u001b[0;32m    736\u001b[0m     attention_probs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, attention_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), attention_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), value_layer\n\u001b[0;32m    737\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\autograd\\function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:113\u001b[0m, in \u001b[0;36mXSoftmax.forward\u001b[1;34m(self, input, mask, dim)\u001b[0m\n\u001b[0;32m    110\u001b[0m rmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m(mask\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool))\n\u001b[0;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mmasked_fill(rmask, torch\u001b[38;5;241m.\u001b[39mtensor(torch\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin))\n\u001b[1;32m--> 113\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim)\n\u001b[0;32m    114\u001b[0m output\u001b[38;5;241m.\u001b[39mmasked_fill_(rmask, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_for_backward(output)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "atepc_result = aspect_extractor.batch_predict(\n",
    "    list(three_star[\"stem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=True,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c74f78",
   "metadata": {},
   "source": [
    "## 4-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28dc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "atepc_result = aspect_extractor.batch_predict(\n",
    "    list(four_star[\"stem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=True,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e6709",
   "metadata": {},
   "source": [
    "## 5-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "atepc_result = aspect_extractor.batch_predict(\n",
    "    list(five_star[\"stem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=True,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1e786-6d56-4dfb-af7c-95064d82eea8",
   "metadata": {},
   "source": [
    "## Pre-Covid 3 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8325f2ca-b667-41b3-a8cf-86aa75aa8010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 12181/12181 [00:18<00:00, 654.85it/s]\n",
      "extracting aspect terms: 100%|██████████| 381/381 [37:28<00:00,  5.90s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 39690/39690 [00:58<00:00, 682.18it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 1241/1241 [1:39:47<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-09 04:46:35] (2.3.4) The results of aspect term extraction have been saved in /Users/ammarbagharib/git/sentiment_analysis_bt4222/codes/aspect_modelling/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atepc_result = aspect_extractor.batch_predict(\n",
    "    list(precovid_3star[\"lem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=True,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b084c9a-133f-455b-ae84-2f67fc292d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'smart clean good location value money second stay ibis bencoolen accor gold member allow early checkin late checkout pm welcome drink breakfast really nice great variety recommend business budget traveller',\n",
       " 'IOB': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ASP',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ASP',\n",
       "  'I-ASP',\n",
       "  'I-ASP',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'tokens': ['smart',\n",
       "  'clean',\n",
       "  'good',\n",
       "  'location',\n",
       "  'value',\n",
       "  'money',\n",
       "  'second',\n",
       "  'stay',\n",
       "  'ibis',\n",
       "  'bencoolen',\n",
       "  'accor',\n",
       "  'gold',\n",
       "  'member',\n",
       "  'allow',\n",
       "  'early',\n",
       "  'checkin',\n",
       "  'late',\n",
       "  'checkout',\n",
       "  'pm',\n",
       "  'welcome',\n",
       "  'drink',\n",
       "  'breakfast',\n",
       "  'really',\n",
       "  'nice',\n",
       "  'great',\n",
       "  'variety',\n",
       "  'recommend',\n",
       "  'business',\n",
       "  'budget',\n",
       "  'traveller'],\n",
       " 'aspect': ['location', 'welcome drink breakfast'],\n",
       " 'position': [[3], [19, 20, 21]],\n",
       " 'sentiment': ['Positive', 'Positive'],\n",
       " 'probs': [[0.0002267445088364184, 0.006421257741749287, 0.993351936340332],\n",
       "  [0.00018259217904414982, 0.03305363655090332, 0.9667637348175049]],\n",
       " 'confidence': [0.9934, 0.9668]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atepc_result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dfb87e-2aa8-4567-9214-83a5a3f88ecc",
   "metadata": {},
   "source": [
    "## Pre-Covid 4 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fd53e05-9da5-43bd-8390-3a4047c14eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 16583/16583 [00:14<00:00, 1155.44it/s]\n",
      "extracting aspect terms: 100%|██████████| 519/519 [38:39<00:00,  4.47s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 51340/51340 [01:18<00:00, 657.07it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 1605/1605 [2:09:58<00:00,  4.86s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-09 07:54:44] (2.3.4) The results of aspect term extraction have been saved in /Users/ammarbagharib/git/sentiment_analysis_bt4222/codes/aspect_modelling/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\n"
     ]
    }
   ],
   "source": [
    "atepc_result2 = aspect_extractor.batch_predict(\n",
    "    list(precovid_4star[\"lem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=False,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d845039-49a1-4f00-8390-ffbb743151a2",
   "metadata": {},
   "source": [
    "## Pre-Covid 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37d8abef-008c-4693-8c47-28906e8d6b63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 27256/27256 [00:47<00:00, 567.89it/s]\n",
      "extracting aspect terms: 100%|██████████| 852/852 [1:25:08<00:00,  6.00s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 89944/89944 [04:07<00:00, 363.19it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 2811/2811 [4:36:08<00:00,  5.89s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-09 18:40:08] (2.3.4) The results of aspect term extraction have been saved in /Users/ammarbagharib/git/sentiment_analysis_bt4222/codes/aspect_modelling/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\n"
     ]
    }
   ],
   "source": [
    "atepc_result3 = aspect_extractor.batch_predict(\n",
    "    list(precovid_5star[\"lem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=False,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc2946-7856-4ade-84a3-1ae90a64347a",
   "metadata": {},
   "source": [
    "## Post-Covid 3 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fff6c31-d3c6-4c2f-bec2-11e8841ea81b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 12181/12181 [00:10<00:00, 1179.19it/s]\n",
      "extracting aspect terms: 100%|██████████| 381/381 [28:24<00:00,  4.47s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 39690/39690 [00:59<00:00, 671.99it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 1241/1241 [1:36:25<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-10 00:10:01] (2.3.4) The results of aspect term extraction have been saved in /Users/ammarbagharib/git/sentiment_analysis_bt4222/codes/aspect_modelling/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\n"
     ]
    }
   ],
   "source": [
    "atepc_result4 = aspect_extractor.batch_predict(\n",
    "    list(precovid_3star[\"lem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=False,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1820bc-243c-4cd4-b153-559e1762e37f",
   "metadata": {},
   "source": [
    "## Post-Covid 4 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e2e671e-145c-4878-826c-d4ef212a6628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 1344/1344 [00:01<00:00, 1212.32it/s]\n",
      "extracting aspect terms: 100%|██████████| 42/42 [02:57<00:00,  4.24s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 4040/4040 [00:05<00:00, 770.28it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 127/127 [11:03<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-09 21:57:35] (2.3.4) The results of aspect term extraction have been saved in /Users/ammarbagharib/git/sentiment_analysis_bt4222/codes/aspect_modelling/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "atepc_result5 = aspect_extractor.batch_predict(\n",
    "    list(postcovid_4star[\"lem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=False,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492d0ff-2076-452b-aed0-e6540e89f441",
   "metadata": {},
   "source": [
    "## Post-Covid 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6ec619d-b3ac-458d-9f2c-8ef08d72f37a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 4387/4387 [00:04<00:00, 1059.45it/s]\n",
      "extracting aspect terms: 100%|██████████| 138/138 [09:38<00:00,  4.19s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 13313/13313 [00:19<00:00, 700.44it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 417/417 [35:13<00:00,  5.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-09 21:04:21] (2.3.4) The results of aspect term extraction have been saved in /Users/ammarbagharib/git/sentiment_analysis_bt4222/codes/aspect_modelling/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\n"
     ]
    }
   ],
   "source": [
    "atepc_result5 = aspect_extractor.batch_predict(\n",
    "    list(postcovid_5star[\"lem_review\"]),  #\n",
    "    save_result=True,\n",
    "    print_result=False,  # print the result\n",
    "    pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "    eval_batch_size=32,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
